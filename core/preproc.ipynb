{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9652210f",
   "metadata": {},
   "source": [
    "## Data Exploration and Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aeb4e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import musdb\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aeb4e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "db = musdb.DB(root=\"Dataset\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "44682c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mus_train = musdb.DB(root='./Dataset', subsets=\"train\")\n",
    "mus_test = musdb.DB(root='./Dataset', subsets=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae481b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 300032, 2)\n",
      "(5, 300032, 2)\n",
      "(5, 300032, 2)\n",
      "(5, 300032, 2)\n",
      "(5, 300032, 2)\n"
     ]
    }
   ],
   "source": [
    "for track in mus_train[:3]:\n",
    "    # print(f\"Name: {track.name} Instruments: {track.stems} Targets: {track.targets}\")\n",
    "    print(track.stems.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "07d4872b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb70316b879047b4bd17adc85a367902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Instrument:', options=('vocals', 'drums', 'bass', 'other', 'accompaniment…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Audio, display\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "\n",
    "track = mus_train[0]  \n",
    "instruments = list(track.targets.keys())\n",
    "\n",
    "first_audio = track.targets[instruments[0]].audio\n",
    "sr = track.rate\n",
    "audio_len = first_audio.shape[0] if hasattr(first_audio, 'shape') else len(first_audio)\n",
    "duration_sec = int(audio_len // sr)\n",
    "\n",
    "dropdown = widgets.Dropdown(options=instruments, description='Instrument:' )\n",
    "slider = widgets.IntSlider(value=0, min=0, max=max(duration_sec-5,0), step=1, description='Start (s):')\n",
    "seg_len = widgets.BoundedIntText(value=5, min=1, max=max(duration_sec,1), description='Length (s):')\n",
    "play_button = widgets.Button(description='Play segment')\n",
    "\n",
    "def play_segment(instrument, start_sec, segment_sec=5):\n",
    "    audio_data = track.targets[instrument].audio\n",
    "    start_sample = int(start_sec * sr)\n",
    "    end_sample = int(min((start_sec + segment_sec) * sr, audio_data.shape[0]))\n",
    "    segment = audio_data[start_sample:end_sample]\n",
    "    print(f'Playing {instrument} from {start_sec}s to {start_sec+segment_sec}s')\n",
    "    if segment.size == 0:\n",
    "        print('Selected range is empty (check start time and length).')\n",
    "        return\n",
    "    if segment.ndim == 1:\n",
    "        display(Audio(segment, rate=sr))\n",
    "    elif segment.ndim == 2:\n",
    "        display(Audio(segment.T, rate=sr))\n",
    "    else:\n",
    "        print(f'Unsupported audio shape for {instrument}: {segment.shape}')\n",
    "\n",
    "def on_play_clicked(b):\n",
    "    play_segment(dropdown.value, int(slider.value), int(seg_len.value))\n",
    "\n",
    "play_button.on_click(on_play_clicked)\n",
    "display(widgets.HBox([dropdown, seg_len, slider, play_button]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dcd451d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional libraries for preprocessing\n",
    "import librosa\n",
    "import scipy.signal\n",
    "from scipy.signal import stft, istft\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe020cba",
   "metadata": {},
   "source": [
    "## Preprocessing Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e7fd0575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing config initialized:\n",
      "Sample rate: 44100 Hz\n",
      "Chunk length: 4.0 seconds\n",
      "FFT size: 4096\n",
      "Hop length: 1024\n",
      "Band edges: [0, 1500, 6000, 22050] Hz\n"
     ]
    }
   ],
   "source": [
    "# Default preprocessing configuration\n",
    "class PreprocessingConfig:\n",
    "    def __init__(self):\n",
    "        self.sample_rate = 44100\n",
    "        self.chunk_len = 4.0  # seconds\n",
    "        self.overlap = 0.0  # configurable to 50%\n",
    "        self.n_fft = 4096  # fallback 2048\n",
    "        self.hop_length = self.n_fft // 4\n",
    "        self.window = 'hann'\n",
    "        self.peak = 0.99\n",
    "        self.eps = 1e-8\n",
    "        self.band_edges_hz = [0, 1500, 6000, self.sample_rate // 2]\n",
    "        self.pad_chunks = True\n",
    "        \n",
    "        # Augmentation flags\n",
    "        self.enable_random_gain = False\n",
    "        self.enable_remix = False\n",
    "        self.enable_time_stretch = False\n",
    "        self.enable_pitch_shift = False\n",
    "        self.enable_add_noise = False\n",
    "        \n",
    "        # Target sources\n",
    "        self.target_sources = ['vocals', 'drums', 'bass', 'other']\n",
    "\n",
    "config = PreprocessingConfig()\n",
    "print(f\"Preprocessing config initialized:\")\n",
    "print(f\"Sample rate: {config.sample_rate} Hz\")\n",
    "print(f\"Chunk length: {config.chunk_len} seconds\")\n",
    "print(f\"FFT size: {config.n_fft}\")\n",
    "print(f\"Hop length: {config.hop_length}\")\n",
    "print(f\"Band edges: {config.band_edges_hz} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ccd31f",
   "metadata": {},
   "source": [
    "## Core Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b8cc6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded track 'A Classic Education - NightOwl' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Sample rate: 44100 Hz\n",
      "vocals: shape (300032, 2), dtype float64\n",
      "drums: shape (300032, 2), dtype float64\n",
      "bass: shape (300032, 2), dtype float64\n",
      "other: shape (300032, 2), dtype float64\n"
     ]
    }
   ],
   "source": [
    "# 1. Track loading & verification\n",
    "def load_track(musdb_track):\n",
    "    \"\"\"\n",
    "    Load track stems and verify all required sources are present.\n",
    "    \n",
    "    Args:\n",
    "        musdb_track: musdb.Track object\n",
    "        \n",
    "    Returns:\n",
    "        stems_dict: dict with stem audio data\n",
    "        sr: sample rate\n",
    "    \"\"\"\n",
    "    stems_dict = {}\n",
    "    sr = musdb_track.rate\n",
    "    \n",
    "    # Extract stems\n",
    "    for source_name in config.target_sources:\n",
    "        if source_name in musdb_track.targets:\n",
    "            stems_dict[source_name] = musdb_track.targets[source_name].audio\n",
    "        else:\n",
    "            print(f\"Warning: Source '{source_name}' not found in track '{musdb_track.name}'\")\n",
    "            # Create silent stem if missing\n",
    "            if len(stems_dict) > 0:\n",
    "                # Use shape from existing stem\n",
    "                ref_shape = next(iter(stems_dict.values())).shape\n",
    "                stems_dict[source_name] = np.zeros(ref_shape, dtype=np.float32)\n",
    "            else:\n",
    "                print(f\"Cannot create silent stem for '{source_name}' - no reference shape available\")\n",
    "                continue\n",
    "    \n",
    "    if not stems_dict:\n",
    "        raise ValueError(f\"No valid stems found in track '{musdb_track.name}'\")\n",
    "        \n",
    "    print(f\"Loaded track '{musdb_track.name}' with sources: {list(stems_dict.keys())}\")\n",
    "    return stems_dict, sr\n",
    "\n",
    "# Test with first track\n",
    "test_stems, test_sr = load_track(mus_train[0])\n",
    "print(f\"Sample rate: {test_sr} Hz\")\n",
    "for source, audio in test_stems.items():\n",
    "    print(f\"{source}: shape {audio.shape}, dtype {audio.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "087aacef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (44100, 2), dtype: float64\n",
      "Resampled shape: (44100, 2), dtype: float32\n",
      "Range: [-0.189, 0.223]\n"
     ]
    }
   ],
   "source": [
    "# 2. Resample + dtype conversion\n",
    "def resample_audio(wav, orig_sr, target_sr):\n",
    "    \"\"\"\n",
    "    Resample audio to target sample rate and convert to float32.\n",
    "    \n",
    "    Args:\n",
    "        wav: audio array\n",
    "        orig_sr: original sample rate\n",
    "        target_sr: target sample rate\n",
    "        \n",
    "    Returns:\n",
    "        wav_resampled: resampled audio as float32\n",
    "    \"\"\"\n",
    "    if orig_sr == target_sr:\n",
    "        return wav.astype(np.float32)\n",
    "    \n",
    "    # Resample using librosa\n",
    "    if wav.ndim == 1:\n",
    "        wav_resampled = librosa.resample(wav, orig_sr=orig_sr, target_sr=target_sr)\n",
    "    else:\n",
    "        # Handle stereo/multi-channel\n",
    "        wav_resampled = np.array([\n",
    "            librosa.resample(wav[:, ch], orig_sr=orig_sr, target_sr=target_sr) \n",
    "            for ch in range(wav.shape[1])\n",
    "        ]).T\n",
    "    \n",
    "    # Convert to float32 and ensure range [-1.0, 1.0]\n",
    "    wav_resampled = wav_resampled.astype(np.float32)\n",
    "    \n",
    "    # Clip to valid range if needed\n",
    "    if np.max(np.abs(wav_resampled)) > 1.0:\n",
    "        print(f\"Warning: Audio clipped during resampling. Max value: {np.max(np.abs(wav_resampled))}\")\n",
    "        wav_resampled = np.clip(wav_resampled, -1.0, 1.0)\n",
    "    \n",
    "    return wav_resampled\n",
    "\n",
    "# Test resampling\n",
    "test_audio = test_stems['vocals'][:44100]  # 1 second\n",
    "resampled = resample_audio(test_audio, test_sr, config.sample_rate)\n",
    "print(f\"Original shape: {test_audio.shape}, dtype: {test_audio.dtype}\")\n",
    "print(f\"Resampled shape: {resampled.shape}, dtype: {resampled.dtype}\")\n",
    "print(f\"Range: [{np.min(resampled):.3f}, {np.max(resampled):.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a02165de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: max=0.223, RMS=0.033\n",
      "Peak normalized: max=0.990\n",
      "RMS normalized: RMS=0.100\n"
     ]
    }
   ],
   "source": [
    "# 3. Normalization functions\n",
    "def normalize_peak(wav, peak=0.99):\n",
    "    \"\"\"\n",
    "    Peak normalize audio to specified peak value.\n",
    "    \n",
    "    Args:\n",
    "        wav: audio array\n",
    "        peak: target peak value (default 0.99)\n",
    "        \n",
    "    Returns:\n",
    "        wav_norm: peak normalized audio\n",
    "    \"\"\"\n",
    "    max_val = np.max(np.abs(wav))\n",
    "    if max_val > 0:\n",
    "        scale_factor = peak / max_val\n",
    "        wav_norm = wav * scale_factor\n",
    "    else:\n",
    "        wav_norm = wav.copy()\n",
    "    \n",
    "    return wav_norm.astype(np.float32)\n",
    "\n",
    "def rms_normalize(wav, target_db=-20):\n",
    "    \"\"\"\n",
    "    RMS normalize audio to target dB level.\n",
    "    \n",
    "    Args:\n",
    "        wav: audio array\n",
    "        target_db: target RMS level in dB\n",
    "        \n",
    "    Returns:\n",
    "        wav_norm: RMS normalized audio\n",
    "    \"\"\"\n",
    "    # Calculate current RMS\n",
    "    rms = np.sqrt(np.mean(wav**2))\n",
    "    if rms > 0:\n",
    "        # Convert target dB to linear scale\n",
    "        target_rms = 10**(target_db / 20)\n",
    "        scale_factor = target_rms / rms\n",
    "        wav_norm = wav * scale_factor\n",
    "    else:\n",
    "        wav_norm = wav.copy()\n",
    "    \n",
    "    return wav_norm.astype(np.float32)\n",
    "\n",
    "# Test normalization\n",
    "test_segment = test_stems['vocals'][:44100]\n",
    "peak_norm = normalize_peak(test_segment, config.peak)\n",
    "rms_norm = rms_normalize(test_segment, target_db=-20)\n",
    "\n",
    "print(f\"Original: max={np.max(np.abs(test_segment)):.3f}, RMS={np.sqrt(np.mean(test_segment**2)):.3f}\")\n",
    "print(f\"Peak normalized: max={np.max(np.abs(peak_norm)):.3f}\")\n",
    "print(f\"RMS normalized: RMS={np.sqrt(np.mean(rms_norm**2)):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bf9aeb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixture shape: (300032, 2)\n",
      "Mixture peak: 0.990\n",
      "Mixture RMS: 0.205\n",
      "vocals_rms: 0.063\n",
      "vocals_peak: 0.616\n",
      "drums_rms: 0.021\n",
      "drums_peak: 0.229\n",
      "bass_rms: 0.134\n",
      "bass_peak: 0.489\n",
      "other_rms: 0.096\n",
      "other_peak: 0.528\n",
      "mixture_peak_before_scaling: 0.858\n",
      "mixture_peak_final: 0.990\n",
      "mixture_rms_final: 0.205\n"
     ]
    }
   ],
   "source": [
    "# 4. Mixture creation and level check\n",
    "def make_mixture(stems_dict, normalize=True, headroom=0.95):\n",
    "    \"\"\"\n",
    "    Create mixture by summing stems with optional scaling to prevent clipping.\n",
    "    \n",
    "    Args:\n",
    "        stems_dict: dict of stem audio arrays\n",
    "        normalize: whether to apply peak normalization\n",
    "        headroom: headroom to maintain when scaling\n",
    "        \n",
    "    Returns:\n",
    "        mixture_wav: summed mixture\n",
    "        metadata: dict with per-stem RMS/peak info\n",
    "    \"\"\"\n",
    "    # Sum all stems\n",
    "    mixture = np.zeros_like(next(iter(stems_dict.values())), dtype=np.float32)\n",
    "    \n",
    "    metadata = {}\n",
    "    for source_name, audio in stems_dict.items():\n",
    "        mixture += audio.astype(np.float32)\n",
    "        \n",
    "        # Record per-stem statistics\n",
    "        metadata[f'{source_name}_rms'] = float(np.sqrt(np.mean(audio**2)))\n",
    "        metadata[f'{source_name}_peak'] = float(np.max(np.abs(audio)))\n",
    "    \n",
    "    # Check for clipping and scale if needed\n",
    "    mixture_peak = np.max(np.abs(mixture))\n",
    "    metadata['mixture_peak_before_scaling'] = float(mixture_peak)\n",
    "    \n",
    "    if mixture_peak > headroom:\n",
    "        scale_factor = headroom / mixture_peak\n",
    "        mixture *= scale_factor\n",
    "        print(f\"Scaled mixture by {scale_factor:.3f} to prevent clipping (peak was {mixture_peak:.3f})\")\n",
    "        \n",
    "        # Also scale individual stems to maintain consistency\n",
    "        for source_name in stems_dict:\n",
    "            stems_dict[source_name] = stems_dict[source_name] * scale_factor\n",
    "    \n",
    "    # Optional peak normalization\n",
    "    if normalize:\n",
    "        mixture = normalize_peak(mixture, config.peak)\n",
    "    \n",
    "    metadata['mixture_peak_final'] = float(np.max(np.abs(mixture)))\n",
    "    metadata['mixture_rms_final'] = float(np.sqrt(np.mean(mixture**2)))\n",
    "    \n",
    "    return mixture, metadata\n",
    "\n",
    "# Test mixture creation\n",
    "test_mixture, mix_metadata = make_mixture(test_stems)\n",
    "print(f\"Mixture shape: {test_mixture.shape}\")\n",
    "print(f\"Mixture peak: {mix_metadata['mixture_peak_final']:.3f}\")\n",
    "print(f\"Mixture RMS: {mix_metadata['mixture_rms_final']:.3f}\")\n",
    "for key, value in mix_metadata.items():\n",
    "    if 'peak' in key or 'rms' in key:\n",
    "        print(f\"{key}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "79adff27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 2 chunks from 6.8s audio\n",
      "Chunk 0: shape (176400, 2), start time 0.0s\n",
      "Chunk 1: shape (176400, 2), start time 4.0s\n"
     ]
    }
   ],
   "source": [
    "# 5. Chunking (fixed-length segments)\n",
    "def chunk_waveform(wav, chunk_len_sec, sr, overlap=0.0, pad=True):\n",
    "    \"\"\"\n",
    "    Split waveform into fixed-length chunks.\n",
    "    \n",
    "    Args:\n",
    "        wav: audio array\n",
    "        chunk_len_sec: chunk length in seconds\n",
    "        sr: sample rate\n",
    "        overlap: overlap fraction (0.0 to 0.9)\n",
    "        pad: whether to pad the last chunk\n",
    "        \n",
    "    Returns:\n",
    "        list of (chunk_array, start_time) tuples\n",
    "    \"\"\"\n",
    "    chunk_len_samples = int(chunk_len_sec * sr)\n",
    "    hop_samples = int(chunk_len_samples * (1 - overlap))\n",
    "    \n",
    "    chunks = []\n",
    "    start_sample = 0\n",
    "    \n",
    "    while start_sample < wav.shape[0]:\n",
    "        end_sample = start_sample + chunk_len_samples\n",
    "        \n",
    "        if end_sample <= wav.shape[0]:\n",
    "            # Full chunk\n",
    "            chunk = wav[start_sample:end_sample]\n",
    "        elif pad:\n",
    "            # Pad last chunk\n",
    "            chunk = np.zeros((chunk_len_samples,) + wav.shape[1:], dtype=wav.dtype)\n",
    "            remaining_samples = wav.shape[0] - start_sample\n",
    "            chunk[:remaining_samples] = wav[start_sample:]\n",
    "        else:\n",
    "            # Skip incomplete chunk\n",
    "            break\n",
    "        \n",
    "        start_time = start_sample / sr\n",
    "        chunks.append((chunk, start_time))\n",
    "        \n",
    "        start_sample += hop_samples\n",
    "        \n",
    "        # Prevent infinite loop\n",
    "        if hop_samples == 0:\n",
    "            break\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Test chunking\n",
    "test_audio_long = test_stems['vocals'][:int(10 * test_sr)]  # 10 seconds\n",
    "chunks = chunk_waveform(test_audio_long, config.chunk_len, test_sr, overlap=0.0, pad=True)\n",
    "print(f\"Created {len(chunks)} chunks from {len(test_audio_long)/test_sr:.1f}s audio\")\n",
    "for i, (chunk, start_time) in enumerate(chunks[:3]):\n",
    "    print(f\"Chunk {i}: shape {chunk.shape}, start time {start_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a9f550c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chunk shape: (176400,)\n",
      "Complex spec shape: (2049, 174)\n",
      "Magnitude shape: (2049, 174)\n",
      "Phase shape: (2049, 174)\n",
      "Magnitude range: [0.000, 0.052]\n",
      "Phase range: [-3.142, 3.142]\n"
     ]
    }
   ],
   "source": [
    "# 6. Spectrogram computation\n",
    "def compute_stft(wav, n_fft, hop_length, window='hann'):\n",
    "    \"\"\"\n",
    "    Compute Short-Time Fourier Transform.\n",
    "    \n",
    "    Args:\n",
    "        wav: audio waveform\n",
    "        n_fft: FFT size\n",
    "        hop_length: hop length\n",
    "        window: window type\n",
    "        \n",
    "    Returns:\n",
    "        complex_spec: complex-valued spectrogram\n",
    "    \"\"\"\n",
    "    # Use scipy STFT for consistency\n",
    "    if wav.ndim == 1:\n",
    "        _, _, complex_spec = stft(wav, nperseg=n_fft, noverlap=n_fft-hop_length, window=window)\n",
    "    else:\n",
    "        # Handle multi-channel\n",
    "        complex_specs = []\n",
    "        for ch in range(wav.shape[1]):\n",
    "            _, _, spec_ch = stft(wav[:, ch], nperseg=n_fft, noverlap=n_fft-hop_length, window=window)\n",
    "            complex_specs.append(spec_ch)\n",
    "        complex_spec = np.stack(complex_specs, axis=-1)\n",
    "    \n",
    "    return complex_spec\n",
    "\n",
    "def magnitude_phase_from_complex(complex_spec):\n",
    "    \"\"\"\n",
    "    Extract magnitude and phase from complex spectrogram.\n",
    "    \n",
    "    Args:\n",
    "        complex_spec: complex-valued spectrogram\n",
    "        \n",
    "    Returns:\n",
    "        mag: magnitude spectrogram\n",
    "        phase: phase spectrogram\n",
    "    \"\"\"\n",
    "    mag = np.abs(complex_spec)\n",
    "    phase = np.angle(complex_spec)\n",
    "    return mag.astype(np.float32), phase.astype(np.float32)\n",
    "\n",
    "# Test STFT computation\n",
    "test_chunk = chunks[0][0]\n",
    "if test_chunk.ndim > 1:\n",
    "    test_chunk = test_chunk[:, 0]  # Use first channel for mono test\n",
    "\n",
    "complex_spec = compute_stft(test_chunk, config.n_fft, config.hop_length, config.window)\n",
    "mag, phase = magnitude_phase_from_complex(complex_spec)\n",
    "\n",
    "print(f\"Test chunk shape: {test_chunk.shape}\")\n",
    "print(f\"Complex spec shape: {complex_spec.shape}\")\n",
    "print(f\"Magnitude shape: {mag.shape}\")\n",
    "print(f\"Phase shape: {phase.shape}\")\n",
    "print(f\"Magnitude range: [{np.min(mag):.3f}, {np.max(mag):.3f}]\")\n",
    "print(f\"Phase range: [{np.min(phase):.3f}, {np.max(phase):.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a22d4f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original mag range: [0.000, 0.052]\n",
      "Log1p compressed range: [0.000, 0.050]\n",
      "Log10 compressed range: [-159.2, -25.8] dB\n"
     ]
    }
   ],
   "source": [
    "# 7. Log compression (optional)\n",
    "def log_compress_magnitude(mag, method='log1p', eps=1e-8):\n",
    "    \"\"\"\n",
    "    Apply log compression to magnitude spectrogram.\n",
    "    \n",
    "    Args:\n",
    "        mag: magnitude spectrogram\n",
    "        method: 'log1p' or 'log10'\n",
    "        eps: small constant for numerical stability\n",
    "        \n",
    "    Returns:\n",
    "        log_mag: log-compressed magnitude\n",
    "    \"\"\"\n",
    "    if method == 'log1p':\n",
    "        log_mag = np.log1p(mag)\n",
    "    elif method == 'log10':\n",
    "        log_mag = 20 * np.log10(mag + eps)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown compression method: {method}\")\n",
    "    \n",
    "    return log_mag.astype(np.float32)\n",
    "\n",
    "# Test log compression\n",
    "log_mag_log1p = log_compress_magnitude(mag, method='log1p')\n",
    "log_mag_log10 = log_compress_magnitude(mag, method='log10', eps=config.eps)\n",
    "\n",
    "print(f\"Original mag range: [{np.min(mag):.3f}, {np.max(mag):.3f}]\")\n",
    "print(f\"Log1p compressed range: [{np.min(log_mag_log1p):.3f}, {np.max(log_mag_log1p):.3f}]\")\n",
    "print(f\"Log10 compressed range: [{np.min(log_mag_log10):.1f}, {np.max(log_mag_log10):.1f}] dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4ceb802d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing spectrograms for all sources...\n",
      "Computed 4 IRM masks\n",
      "vocals IRM: shape (2049, 174), range [0.083, 1.000]\n",
      "drums IRM: shape (2049, 174), range [0.000, 1.000]\n",
      "bass IRM: shape (2049, 174), range [0.000, 1.000]\n",
      "other IRM: shape (2049, 174), range [0.000, 1.000]\n",
      "Computed 4 IRM masks\n",
      "vocals IRM: shape (2049, 174), range [0.083, 1.000]\n",
      "drums IRM: shape (2049, 174), range [0.000, 1.000]\n",
      "bass IRM: shape (2049, 174), range [0.000, 1.000]\n",
      "other IRM: shape (2049, 174), range [0.000, 1.000]\n"
     ]
    }
   ],
   "source": [
    "# 8. Mask target creation\n",
    "def compute_irm_masks(sources_mag_list, mixture_mag, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Compute Ideal Ratio Masks (IRM) for source separation.\n",
    "    \n",
    "    Args:\n",
    "        sources_mag_list: list of source magnitude spectrograms\n",
    "        mixture_mag: mixture magnitude spectrogram\n",
    "        eps: small constant for numerical stability\n",
    "        \n",
    "    Returns:\n",
    "        irm_masks: list of IRM masks clipped to [0,1]\n",
    "    \"\"\"\n",
    "    irm_masks = []\n",
    "    \n",
    "    for source_mag in sources_mag_list:\n",
    "        # IRM = source_mag / (mixture_mag + eps)\n",
    "        irm = source_mag / (mixture_mag + eps)\n",
    "        # Clip to [0, 1] range\n",
    "        irm = np.clip(irm, 0.0, 1.0)\n",
    "        irm_masks.append(irm.astype(np.float32))\n",
    "    \n",
    "    return irm_masks\n",
    "\n",
    "def compute_cirm_masks(sources_complex, mixture_complex, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Compute Complex Ideal Ratio Masks (cIRM) for phase-aware models.\n",
    "    \n",
    "    Args:\n",
    "        sources_complex: list of source complex spectrograms\n",
    "        mixture_complex: mixture complex spectrogram\n",
    "        eps: small constant for numerical stability\n",
    "        \n",
    "    Returns:\n",
    "        cirm_masks: list of complex IRM masks\n",
    "    \"\"\"\n",
    "    cirm_masks = []\n",
    "    \n",
    "    for source_complex in sources_complex:\n",
    "        # cIRM = source_complex / (mixture_complex + eps)\n",
    "        cirm = source_complex / (mixture_complex + eps)\n",
    "        cirm_masks.append(cirm.astype(np.complex64))\n",
    "    \n",
    "    return cirm_masks\n",
    "\n",
    "# Test mask computation - we need source spectrograms first\n",
    "print(\"Computing spectrograms for all sources...\")\n",
    "test_mixture_chunk = chunks[0][0]\n",
    "if test_mixture_chunk.ndim > 1:\n",
    "    test_mixture_chunk = test_mixture_chunk[:, 0]\n",
    "\n",
    "# Get a test chunk from all sources\n",
    "test_sources_chunks = {}\n",
    "for source_name in config.target_sources:\n",
    "    source_chunks = chunk_waveform(test_stems[source_name], config.chunk_len, test_sr)\n",
    "    source_chunk = source_chunks[0][0]\n",
    "    if source_chunk.ndim > 1:\n",
    "        source_chunk = source_chunk[:, 0]\n",
    "    test_sources_chunks[source_name] = source_chunk\n",
    "\n",
    "# Compute spectrograms for all sources\n",
    "sources_complex = []\n",
    "sources_mag = []\n",
    "\n",
    "for source_name in config.target_sources:\n",
    "    source_complex = compute_stft(test_sources_chunks[source_name], config.n_fft, config.hop_length)\n",
    "    source_mag, _ = magnitude_phase_from_complex(source_complex)\n",
    "    sources_complex.append(source_complex)\n",
    "    sources_mag.append(source_mag)\n",
    "\n",
    "# Compute mixture spectrogram\n",
    "mixture_complex = compute_stft(test_mixture_chunk, config.n_fft, config.hop_length)\n",
    "mixture_mag, _ = magnitude_phase_from_complex(mixture_complex)\n",
    "\n",
    "# Compute IRM masks\n",
    "irm_masks = compute_irm_masks(sources_mag, mixture_mag, config.eps)\n",
    "\n",
    "print(f\"Computed {len(irm_masks)} IRM masks\")\n",
    "for i, (source_name, mask) in enumerate(zip(config.target_sources, irm_masks)):\n",
    "    print(f\"{source_name} IRM: shape {mask.shape}, range [{np.min(mask):.3f}, {np.max(mask):.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3a61b452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 3 frequency bands:\n",
      "Band 0 (0-1500 Hz): shape (139, 174)\n",
      "  Original range: [0.000, 0.052]\n",
      "  Normalized range: [-0.629, 10.720]\n",
      "Band 1 (1500-6000 Hz): shape (418, 174)\n",
      "  Original range: [0.000, 0.013]\n",
      "  Normalized range: [-0.422, 28.547]\n",
      "Band 2 (6000-22050 Hz): shape (1491, 174)\n",
      "  Original range: [0.000, 0.001]\n",
      "  Normalized range: [-0.400, 19.627]\n"
     ]
    }
   ],
   "source": [
    "# 9. Band-splitting utilities\n",
    "def split_bands(mag, sr, n_fft, band_edges_hz):\n",
    "    \"\"\"\n",
    "    Split frequency axis into bands.\n",
    "    \n",
    "    Args:\n",
    "        mag: magnitude spectrogram\n",
    "        sr: sample rate\n",
    "        n_fft: FFT size\n",
    "        band_edges_hz: list of band edge frequencies in Hz\n",
    "        \n",
    "    Returns:\n",
    "        bands: list of band magnitude spectrograms\n",
    "    \"\"\"\n",
    "    # Convert Hz to bin indices\n",
    "    freq_bins = np.linspace(0, sr/2, n_fft//2 + 1)\n",
    "    band_indices = []\n",
    "    \n",
    "    for freq_hz in band_edges_hz:\n",
    "        bin_idx = np.argmin(np.abs(freq_bins - freq_hz))\n",
    "        band_indices.append(bin_idx)\n",
    "    \n",
    "    bands = []\n",
    "    for i in range(len(band_indices) - 1):\n",
    "        start_bin = band_indices[i]\n",
    "        end_bin = band_indices[i + 1]\n",
    "        band_mag = mag[start_bin:end_bin, :]\n",
    "        bands.append(band_mag)\n",
    "    \n",
    "    return bands\n",
    "\n",
    "def normalize_bands(bands, method='mean_std'):\n",
    "    \"\"\"\n",
    "    Normalize bands using mean/std or min/max.\n",
    "    \n",
    "    Args:\n",
    "        bands: list of band spectrograms\n",
    "        method: 'mean_std' or 'min_max'\n",
    "        \n",
    "    Returns:\n",
    "        normalized_bands: list of normalized bands\n",
    "        normalization_stats: dict with stats for denormalization\n",
    "    \"\"\"\n",
    "    normalized_bands = []\n",
    "    normalization_stats = {}\n",
    "    \n",
    "    for i, band in enumerate(bands):\n",
    "        if method == 'mean_std':\n",
    "            mean_val = np.mean(band)\n",
    "            std_val = np.std(band)\n",
    "            normalized_band = (band - mean_val) / (std_val + config.eps)\n",
    "            normalization_stats[f'band_{i}'] = {'mean': mean_val, 'std': std_val}\n",
    "        elif method == 'min_max':\n",
    "            min_val = np.min(band)\n",
    "            max_val = np.max(band)\n",
    "            normalized_band = (band - min_val) / (max_val - min_val + config.eps)\n",
    "            normalization_stats[f'band_{i}'] = {'min': min_val, 'max': max_val}\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown normalization method: {method}\")\n",
    "        \n",
    "        normalized_bands.append(normalized_band.astype(np.float32))\n",
    "    \n",
    "    return normalized_bands, normalization_stats\n",
    "\n",
    "# Test band splitting\n",
    "bands = split_bands(mixture_mag, config.sample_rate, config.n_fft, config.band_edges_hz)\n",
    "normalized_bands, band_stats = normalize_bands(bands, method='mean_std')\n",
    "\n",
    "print(f\"Split into {len(bands)} frequency bands:\")\n",
    "for i, (band, norm_band) in enumerate(zip(bands, normalized_bands)):\n",
    "    freq_start = config.band_edges_hz[i]\n",
    "    freq_end = config.band_edges_hz[i+1]\n",
    "    print(f\"Band {i} ({freq_start}-{freq_end} Hz): shape {band.shape}\")\n",
    "    print(f\"  Original range: [{np.min(band):.3f}, {np.max(band):.3f}]\")\n",
    "    print(f\"  Normalized range: [{np.min(norm_band):.3f}, {np.max(norm_band):.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d3e3fe",
   "metadata": {},
   "source": [
    "## Data Augmentation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "59e34a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing augmentation functions...\n",
      "Original RMS: 0.046\n",
      "Gained RMS: 0.042\n",
      "Noisy RMS: 0.046\n",
      "Augmentation functions ready!\n"
     ]
    }
   ],
   "source": [
    "# 10. Augmentation functions\n",
    "def random_gain(wav, gain_range_db=(-6, 6), seed=None):\n",
    "    \"\"\"\n",
    "    Apply random gain augmentation.\n",
    "    \n",
    "    Args:\n",
    "        wav: audio waveform\n",
    "        gain_range_db: tuple of (min_db, max_db)\n",
    "        seed: random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        augmented_wav: gain-augmented audio\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    gain_db = np.random.uniform(gain_range_db[0], gain_range_db[1])\n",
    "    gain_linear = 10**(gain_db / 20)\n",
    "    \n",
    "    return wav * gain_linear\n",
    "\n",
    "def add_noise(wav, snr_range_db=(10, 30), seed=None):\n",
    "    \"\"\"\n",
    "    Add white noise at specified SNR range.\n",
    "    \n",
    "    Args:\n",
    "        wav: audio waveform\n",
    "        snr_range_db: tuple of (min_snr, max_snr) in dB\n",
    "        seed: random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        noisy_wav: audio with added noise\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    # Calculate signal power\n",
    "    signal_power = np.mean(wav**2)\n",
    "    \n",
    "    # Target SNR\n",
    "    target_snr_db = np.random.uniform(snr_range_db[0], snr_range_db[1])\n",
    "    target_snr_linear = 10**(target_snr_db / 10)\n",
    "    \n",
    "    # Calculate noise power\n",
    "    noise_power = signal_power / target_snr_linear\n",
    "    \n",
    "    # Generate and add noise\n",
    "    noise = np.random.normal(0, np.sqrt(noise_power), wav.shape)\n",
    "    \n",
    "    return wav + noise.astype(wav.dtype)\n",
    "\n",
    "def time_stretch(wav, sr, stretch_range=(0.9, 1.1), seed=None):\n",
    "    \"\"\"\n",
    "    Apply time stretching without changing pitch.\n",
    "    \n",
    "    Args:\n",
    "        wav: audio waveform\n",
    "        sr: sample rate\n",
    "        stretch_range: tuple of (min_rate, max_rate)\n",
    "        seed: random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        stretched_wav: time-stretched audio\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    stretch_rate = np.random.uniform(stretch_range[0], stretch_range[1])\n",
    "    \n",
    "    # Use librosa for time stretching\n",
    "    stretched_wav = librosa.effects.time_stretch(wav, rate=stretch_rate)\n",
    "    \n",
    "    return stretched_wav\n",
    "\n",
    "def pitch_shift(wav, sr, semitone_range=(-2, 2), seed=None):\n",
    "    \"\"\"\n",
    "    Apply pitch shifting.\n",
    "    \n",
    "    Args:\n",
    "        wav: audio waveform\n",
    "        sr: sample rate\n",
    "        semitone_range: tuple of (min_semitones, max_semitones)\n",
    "        seed: random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        shifted_wav: pitch-shifted audio\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    n_steps = np.random.uniform(semitone_range[0], semitone_range[1])\n",
    "    \n",
    "    # Use librosa for pitch shifting\n",
    "    shifted_wav = librosa.effects.pitch_shift(wav, sr=sr, n_steps=n_steps)\n",
    "    \n",
    "    return shifted_wav\n",
    "\n",
    "# Test augmentations\n",
    "print(\"Testing augmentation functions...\")\n",
    "test_aug_audio = test_mixture_chunk[:44100]  # 1 second\n",
    "\n",
    "# Random gain\n",
    "gained_audio = random_gain(test_aug_audio, gain_range_db=(-3, 3), seed=42)\n",
    "print(f\"Original RMS: {np.sqrt(np.mean(test_aug_audio**2)):.3f}\")\n",
    "print(f\"Gained RMS: {np.sqrt(np.mean(gained_audio**2)):.3f}\")\n",
    "\n",
    "# Add noise\n",
    "noisy_audio = add_noise(test_aug_audio, snr_range_db=(15, 25), seed=42)\n",
    "print(f\"Noisy RMS: {np.sqrt(np.mean(noisy_audio**2)):.3f}\")\n",
    "\n",
    "print(\"Augmentation functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee902e4",
   "metadata": {},
   "source": [
    "## Data Saving and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8bccaad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All fields passed validation!\n",
      "Saved chunk to processed_chunks\\test_chunk_0.npz\n",
      "Saved chunk to processed_chunks\\test_chunk_0.npz\n"
     ]
    }
   ],
   "source": [
    "# 11. Save per-chunk artifacts\n",
    "def save_chunk_npz(path, **fields):\n",
    "    \"\"\"\n",
    "    Save chunk data to compressed .npz file.\n",
    "    \n",
    "    Args:\n",
    "        path: output file path\n",
    "        **fields: keyword arguments with data fields\n",
    "    \"\"\"\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    \n",
    "    # Handle special cases for list fields\n",
    "    processed_fields = {}\n",
    "    for key, value in fields.items():\n",
    "        if key == 'bands' and isinstance(value, list):\n",
    "            # Save bands as separate arrays\n",
    "            for i, band in enumerate(value):\n",
    "                processed_fields[f'band_{i}'] = band\n",
    "        elif key == 'sources_wav' and isinstance(value, list):\n",
    "            # Save sources as separate arrays  \n",
    "            for i, source in enumerate(value):\n",
    "                processed_fields[f'source_{i}'] = source\n",
    "        elif key == 'irm_masks' and isinstance(value, list):\n",
    "            # Save IRM masks as separate arrays\n",
    "            for i, mask in enumerate(value):\n",
    "                processed_fields[f'irm_mask_{i}'] = mask\n",
    "        else:\n",
    "            processed_fields[key] = value\n",
    "    \n",
    "    # Save with compression\n",
    "    np.savez_compressed(path, **processed_fields)\n",
    "    print(f\"Saved chunk to {path}\")\n",
    "\n",
    "def validate_chunk_fields(fields_dict):\n",
    "    \"\"\"\n",
    "    Validate chunk fields for sanity checks.\n",
    "    \n",
    "    Args:\n",
    "        fields_dict: dict with chunk data\n",
    "        \n",
    "    Returns:\n",
    "        warnings: list of warning messages\n",
    "    \"\"\"\n",
    "    warnings = []\n",
    "    \n",
    "    # Check for NaN/Inf values\n",
    "    for field_name, data in fields_dict.items():\n",
    "        if isinstance(data, np.ndarray):\n",
    "            if np.any(np.isnan(data)):\n",
    "                warnings.append(f\"Found NaN values in {field_name}\")\n",
    "            if np.any(np.isinf(data)):\n",
    "                warnings.append(f\"Found Inf values in {field_name}\")\n",
    "        elif isinstance(data, list):\n",
    "            # Check list elements\n",
    "            for i, item in enumerate(data):\n",
    "                if isinstance(item, np.ndarray):\n",
    "                    if np.any(np.isnan(item)):\n",
    "                        warnings.append(f\"Found NaN values in {field_name}[{i}]\")\n",
    "                    if np.any(np.isinf(item)):\n",
    "                        warnings.append(f\"Found Inf values in {field_name}[{i}]\")\n",
    "    \n",
    "    # Check IRM mask ranges\n",
    "    if 'irm_masks' in fields_dict:\n",
    "        for i, mask in enumerate(fields_dict['irm_masks']):\n",
    "            if np.any(mask < 0) or np.any(mask > 1):\n",
    "                warnings.append(f\"IRM mask {i} contains values outside [0,1] range\")\n",
    "    \n",
    "    # Check audio ranges\n",
    "    for field_name in ['mixture_wav']:\n",
    "        if field_name in fields_dict:\n",
    "            data = fields_dict[field_name]\n",
    "            if isinstance(data, np.ndarray):\n",
    "                if np.max(np.abs(data)) > 1.1:\n",
    "                    warnings.append(f\"{field_name} contains values > 1.1\")\n",
    "    \n",
    "    # Check sources_wav ranges\n",
    "    if 'sources_wav' in fields_dict:\n",
    "        for i, source in enumerate(fields_dict['sources_wav']):\n",
    "            if isinstance(source, np.ndarray):\n",
    "                if np.max(np.abs(source)) > 1.1:\n",
    "                    warnings.append(f\"sources_wav[{i}] contains values > 1.1\")\n",
    "    \n",
    "    return warnings\n",
    "\n",
    "# Test saving and validation\n",
    "test_fields = {\n",
    "    'mixture_wav': test_mixture_chunk,\n",
    "    'sources_wav': [test_sources_chunks[name] for name in config.target_sources],\n",
    "    'mag': mixture_mag,\n",
    "    'phase': phase,\n",
    "    'log_mag': log_mag_log1p,\n",
    "    'irm_masks': irm_masks,\n",
    "    'bands': bands,\n",
    "    'metadata': {\n",
    "        'sr': config.sample_rate,\n",
    "        'start_time': 0.0,\n",
    "        'track_name': 'test_track',\n",
    "        'channel_count': 1,\n",
    "        'n_fft': config.n_fft,\n",
    "        'hop_length': config.hop_length\n",
    "    }\n",
    "}\n",
    "\n",
    "# Validate fields\n",
    "validation_warnings = validate_chunk_fields(test_fields)\n",
    "if validation_warnings:\n",
    "    print(\"Validation warnings:\")\n",
    "    for warning in validation_warnings:\n",
    "        print(f\"  - {warning}\")\n",
    "else:\n",
    "    print(\"All fields passed validation!\")\n",
    "\n",
    "# Save test chunk\n",
    "output_dir = Path(\"processed_chunks\")\n",
    "test_chunk_path = output_dir / \"test_chunk_0.npz\"\n",
    "save_chunk_npz(test_chunk_path, **test_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e4d732d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing oracle reconstruction...\n",
      "vocals:\n",
      "  SI-SDR: 103.06 dB\n",
      "  Energy ratio: 1.000\n",
      "  Original RMS: 0.074\n",
      "  Reconstructed RMS: 0.074\n",
      "drums:\n",
      "  SI-SDR: -37.45 dB\n",
      "  Energy ratio: 0.046\n",
      "  Original RMS: 0.022\n",
      "  Reconstructed RMS: 0.005\n",
      "bass:\n",
      "  SI-SDR: -40.13 dB\n",
      "  Energy ratio: 0.002\n",
      "  Original RMS: 0.131\n",
      "  Reconstructed RMS: 0.006\n",
      "other:\n",
      "  SI-SDR: -45.58 dB\n",
      "  Energy ratio: 0.124\n",
      "  Original RMS: 0.052\n",
      "  Reconstructed RMS: 0.018\n",
      "\n",
      "Oracle reconstruction test completed!\n"
     ]
    }
   ],
   "source": [
    "# 12. Sanity checks and reconstruction\n",
    "def reconstruct_from_mask(mixture_complex, irm_mask):\n",
    "    \"\"\"\n",
    "    Reconstruct source audio using IRM and mixture phase.\n",
    "    \n",
    "    Args:\n",
    "        mixture_complex: complex mixture spectrogram\n",
    "        irm_mask: ideal ratio mask\n",
    "        \n",
    "    Returns:\n",
    "        reconstructed_audio: reconstructed time-domain audio\n",
    "    \"\"\"\n",
    "    # Apply mask to mixture\n",
    "    reconstructed_complex = mixture_complex * irm_mask\n",
    "    \n",
    "    # Inverse STFT\n",
    "    _, reconstructed_audio = istft(reconstructed_complex, \n",
    "                                   nperseg=config.n_fft, \n",
    "                                   noverlap=config.n_fft-config.hop_length)\n",
    "    \n",
    "    return reconstructed_audio.astype(np.float32)\n",
    "\n",
    "def compute_si_sdr(reference, estimate, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Compute Scale-Invariant Signal-to-Distortion Ratio (SI-SDR).\n",
    "    \n",
    "    Args:\n",
    "        reference: reference signal\n",
    "        estimate: estimated signal\n",
    "        eps: small constant for numerical stability\n",
    "        \n",
    "    Returns:\n",
    "        si_sdr: SI-SDR in dB\n",
    "    \"\"\"\n",
    "    # Ensure same length\n",
    "    min_len = min(len(reference), len(estimate))\n",
    "    reference = reference[:min_len]\n",
    "    estimate = estimate[:min_len]\n",
    "    \n",
    "    # Zero-mean\n",
    "    reference = reference - np.mean(reference)\n",
    "    estimate = estimate - np.mean(estimate)\n",
    "    \n",
    "    # Compute scale factor\n",
    "    alpha = np.sum(reference * estimate) / (np.sum(reference**2) + eps)\n",
    "    \n",
    "    # Scaled reference\n",
    "    scaled_ref = alpha * reference\n",
    "    \n",
    "    # Compute SI-SDR\n",
    "    signal_power = np.sum(scaled_ref**2)\n",
    "    noise_power = np.sum((estimate - scaled_ref)**2)\n",
    "    \n",
    "    si_sdr = 10 * np.log10(signal_power / (noise_power + eps) + eps)\n",
    "    \n",
    "    return si_sdr\n",
    "\n",
    "# Test reconstruction for each source\n",
    "print(\"Testing oracle reconstruction...\")\n",
    "reconstruction_results = {}\n",
    "\n",
    "for i, source_name in enumerate(config.target_sources):\n",
    "    # Reconstruct using IRM\n",
    "    reconstructed = reconstruct_from_mask(mixture_complex, irm_masks[i])\n",
    "    \n",
    "    # Compare with original\n",
    "    original = test_sources_chunks[source_name]\n",
    "    \n",
    "    # Compute metrics\n",
    "    si_sdr = compute_si_sdr(original, reconstructed)\n",
    "    \n",
    "    # Energy comparison\n",
    "    original_energy = np.sum(original**2)\n",
    "    reconstructed_energy = np.sum(reconstructed**2)\n",
    "    energy_ratio = reconstructed_energy / (original_energy + config.eps)\n",
    "    \n",
    "    reconstruction_results[source_name] = {\n",
    "        'si_sdr_db': si_sdr,\n",
    "        'energy_ratio': energy_ratio,\n",
    "        'original_rms': float(np.sqrt(np.mean(original**2))),\n",
    "        'reconstructed_rms': float(np.sqrt(np.mean(reconstructed**2)))\n",
    "    }\n",
    "    \n",
    "    print(f\"{source_name}:\")\n",
    "    print(f\"  SI-SDR: {si_sdr:.2f} dB\")\n",
    "    print(f\"  Energy ratio: {energy_ratio:.3f}\")\n",
    "    print(f\"  Original RMS: {reconstruction_results[source_name]['original_rms']:.3f}\")\n",
    "    print(f\"  Reconstructed RMS: {reconstruction_results[source_name]['reconstructed_rms']:.3f}\")\n",
    "\n",
    "print(f\"\\nOracle reconstruction test completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609c2c60",
   "metadata": {},
   "source": [
    "## Complete Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4f47ace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete preprocessing pipeline\n",
    "def preprocess_track(musdb_track, config, output_dir, apply_augmentations=False, augmentation_seed=None):\n",
    "    \"\"\"\n",
    "    Complete preprocessing pipeline for a single MUSDB track.\n",
    "    \n",
    "    Args:\n",
    "        musdb_track: musdb.Track object\n",
    "        config: PreprocessingConfig object\n",
    "        output_dir: output directory for processed chunks\n",
    "        apply_augmentations: whether to apply data augmentations\n",
    "        augmentation_seed: seed for reproducible augmentations\n",
    "        \n",
    "    Returns:\n",
    "        processing_summary: dict with processing statistics\n",
    "    \"\"\"\n",
    "    print(f\"Processing track: {musdb_track.name}\")\n",
    "    \n",
    "    # 1. Load track\n",
    "    stems_dict, orig_sr = load_track(musdb_track)\n",
    "    \n",
    "    # 2. Resample if needed\n",
    "    if orig_sr != config.sample_rate:\n",
    "        print(f\"Resampling from {orig_sr} Hz to {config.sample_rate} Hz\")\n",
    "        for source_name in stems_dict:\n",
    "            stems_dict[source_name] = resample_audio(stems_dict[source_name], orig_sr, config.sample_rate)\n",
    "    \n",
    "    # 3. Normalize stems\n",
    "    for source_name in stems_dict:\n",
    "        stems_dict[source_name] = normalize_peak(stems_dict[source_name], config.peak)\n",
    "    \n",
    "    # 4. Create mixture\n",
    "    mixture, mix_metadata = make_mixture(stems_dict)\n",
    "    \n",
    "    # 5. Apply augmentations if enabled\n",
    "    if apply_augmentations:\n",
    "        if config.enable_random_gain:\n",
    "            for source_name in stems_dict:\n",
    "                stems_dict[source_name] = random_gain(stems_dict[source_name], seed=augmentation_seed)\n",
    "            mixture, _ = make_mixture(stems_dict)\n",
    "        \n",
    "        if config.enable_add_noise:\n",
    "            mixture = add_noise(mixture, seed=augmentation_seed)\n",
    "    \n",
    "    # 6. Chunk the audio\n",
    "    mixture_chunks = chunk_waveform(mixture, config.chunk_len, config.sample_rate, \n",
    "                                   config.overlap, config.pad_chunks)\n",
    "    \n",
    "    # Chunk all sources\n",
    "    sources_chunks = {}\n",
    "    for source_name in config.target_sources:\n",
    "        source_chunks = chunk_waveform(stems_dict[source_name], config.chunk_len, \n",
    "                                      config.sample_rate, config.overlap, config.pad_chunks)\n",
    "        sources_chunks[source_name] = source_chunks\n",
    "    \n",
    "    # 7. Process each chunk\n",
    "    chunk_count = 0\n",
    "    processing_summary = {\n",
    "        'track_name': musdb_track.name,\n",
    "        'total_chunks': len(mixture_chunks),\n",
    "        'processed_chunks': 0,\n",
    "        'failed_chunks': 0,\n",
    "        'warnings': [],\n",
    "        'metadata': mix_metadata\n",
    "    }\n",
    "    \n",
    "    for chunk_idx, (mixture_chunk, start_time) in enumerate(mixture_chunks):\n",
    "        try:\n",
    "            # Ensure we have corresponding source chunks\n",
    "            sources_chunk_dict = {}\n",
    "            sources_wav_list = []\n",
    "            \n",
    "            for source_name in config.target_sources:\n",
    "                if chunk_idx < len(sources_chunks[source_name]):\n",
    "                    source_chunk, _ = sources_chunks[source_name][chunk_idx]\n",
    "                    sources_chunk_dict[source_name] = source_chunk\n",
    "                    sources_wav_list.append(source_chunk)\n",
    "                else:\n",
    "                    # Handle case where we have fewer source chunks\n",
    "                    print(f\"Warning: Missing source chunk for {source_name} at index {chunk_idx}\")\n",
    "                    continue\n",
    "            \n",
    "            if len(sources_wav_list) != len(config.target_sources):\n",
    "                print(f\"Skipping chunk {chunk_idx} due to missing sources\")\n",
    "                continue\n",
    "            \n",
    "            # Convert to mono if multi-channel for STFT processing\n",
    "            if mixture_chunk.ndim > 1:\n",
    "                mixture_mono = mixture_chunk[:, 0]\n",
    "                sources_mono = [chunk[:, 0] for chunk in sources_wav_list]\n",
    "            else:\n",
    "                mixture_mono = mixture_chunk\n",
    "                sources_mono = sources_wav_list\n",
    "            \n",
    "            # 8. Compute spectrograms\n",
    "            mixture_complex = compute_stft(mixture_mono, config.n_fft, config.hop_length, config.window)\n",
    "            mixture_mag, mixture_phase = magnitude_phase_from_complex(mixture_complex)\n",
    "            \n",
    "            sources_complex = []\n",
    "            sources_mag = []\n",
    "            for source_chunk in sources_mono:\n",
    "                source_complex = compute_stft(source_chunk, config.n_fft, config.hop_length, config.window)\n",
    "                source_mag, _ = magnitude_phase_from_complex(source_complex)\n",
    "                sources_complex.append(source_complex)\n",
    "                sources_mag.append(source_mag)\n",
    "            \n",
    "            # 9. Compute log magnitude\n",
    "            log_mag = log_compress_magnitude(mixture_mag, method='log1p')\n",
    "            \n",
    "            # 10. Compute IRM masks\n",
    "            irm_masks = compute_irm_masks(sources_mag, mixture_mag, config.eps)\n",
    "            \n",
    "            # 11. Split into bands\n",
    "            bands = split_bands(mixture_mag, config.sample_rate, config.n_fft, config.band_edges_hz)\n",
    "            \n",
    "            # 12. Prepare chunk data\n",
    "            chunk_data = {\n",
    "                'mixture_wav': mixture_chunk,\n",
    "                'sources_wav': sources_wav_list,\n",
    "                'mag': mixture_mag,\n",
    "                'phase': mixture_phase,\n",
    "                'log_mag': log_mag,\n",
    "                'irm_masks': irm_masks,\n",
    "                'bands': bands,\n",
    "                'sr': config.sample_rate,\n",
    "                'start_time': start_time,\n",
    "                'track_name': musdb_track.name,\n",
    "                'channel_count': mixture_chunk.shape[1] if mixture_chunk.ndim > 1 else 1,\n",
    "                'n_fft': config.n_fft,\n",
    "                'hop_length': config.hop_length,\n",
    "                'chunk_index': chunk_idx\n",
    "            }\n",
    "            \n",
    "            # 13. Validate chunk\n",
    "            warnings = validate_chunk_fields(chunk_data)\n",
    "            if warnings:\n",
    "                processing_summary['warnings'].extend([f\"Chunk {chunk_idx}: {w}\" for w in warnings])\n",
    "            \n",
    "            # 14. Save chunk\n",
    "            chunk_filename = f\"{musdb_track.name}_chunk_{chunk_idx:03d}.npz\"\n",
    "            chunk_path = Path(output_dir) / chunk_filename\n",
    "            save_chunk_npz(chunk_path, **chunk_data)\n",
    "            \n",
    "            processing_summary['processed_chunks'] += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing chunk {chunk_idx}: {str(e)}\")\n",
    "            processing_summary['failed_chunks'] += 1\n",
    "            processing_summary['warnings'].append(f\"Chunk {chunk_idx}: Processing failed - {str(e)}\")\n",
    "    \n",
    "    print(f\"Completed processing {musdb_track.name}: {processing_summary['processed_chunks']} chunks processed, {processing_summary['failed_chunks']} failed\")\n",
    "    \n",
    "    return processing_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b64f74a",
   "metadata": {},
   "source": [
    "## Unit Tests and Quality Assurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bf339303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running unit tests...\n",
      "Loaded track 'A Classic Education - NightOwl' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "✓ Track loading: Loaded 4 sources at 44100 Hz\n",
      "✓ Audio resampling: Output dtype: float32, max: 0.223\n",
      "✓ Peak normalization: Peak: 0.990\n",
      "✓ Mixture creation: Shape: (300032, 2)\n",
      "✓ Audio chunking: Created 2 chunks\n",
      "✓ STFT computation: Spec shape: (2049, 174)\n",
      "✓ IRM mask computation: Created 4 masks, all in [0,1]: True\n",
      "✓ Band splitting: Created 3 bands\n",
      "✓ Field validation: Validation returned 0 warnings\n",
      "✓ Oracle reconstruction: Reconstructed shape: (177152,)\n",
      "\n",
      "Unit test summary: 10 passed, 0 failed\n",
      "Loaded track 'A Classic Education - NightOwl' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "✓ Track loading: Loaded 4 sources at 44100 Hz\n",
      "✓ Audio resampling: Output dtype: float32, max: 0.223\n",
      "✓ Peak normalization: Peak: 0.990\n",
      "✓ Mixture creation: Shape: (300032, 2)\n",
      "✓ Audio chunking: Created 2 chunks\n",
      "✓ STFT computation: Spec shape: (2049, 174)\n",
      "✓ IRM mask computation: Created 4 masks, all in [0,1]: True\n",
      "✓ Band splitting: Created 3 bands\n",
      "✓ Field validation: Validation returned 0 warnings\n",
      "✓ Oracle reconstruction: Reconstructed shape: (177152,)\n",
      "\n",
      "Unit test summary: 10 passed, 0 failed\n"
     ]
    }
   ],
   "source": [
    "# 13. Unit tests\n",
    "def run_unit_tests():\n",
    "    \"\"\"\n",
    "    Run automated unit tests on the preprocessing pipeline.\n",
    "    \n",
    "    Returns:\n",
    "        test_results: dict with test results\n",
    "    \"\"\"\n",
    "    test_results = {\n",
    "        'passed': 0,\n",
    "        'failed': 0,\n",
    "        'tests': []\n",
    "    }\n",
    "    \n",
    "    def add_test_result(test_name, passed, message=\"\"):\n",
    "        test_results['tests'].append({\n",
    "            'name': test_name,\n",
    "            'passed': passed,\n",
    "            'message': message\n",
    "        })\n",
    "        if passed:\n",
    "            test_results['passed'] += 1\n",
    "        else:\n",
    "            test_results['failed'] += 1\n",
    "        print(f\"{'✓' if passed else '✗'} {test_name}{': ' + message if message else ''}\")\n",
    "    \n",
    "    try:\n",
    "        print(\"Running unit tests...\")\n",
    "        \n",
    "        # Test 1: Track loading\n",
    "        test_track = mus_train[0]\n",
    "        stems, sr = load_track(test_track)\n",
    "        add_test_result(\"Track loading\", \n",
    "                       len(stems) == len(config.target_sources) and sr > 0,\n",
    "                       f\"Loaded {len(stems)} sources at {sr} Hz\")\n",
    "        \n",
    "        # Test 2: Resampling\n",
    "        test_audio = stems['vocals'][:44100]\n",
    "        resampled = resample_audio(test_audio, sr, config.sample_rate)\n",
    "        add_test_result(\"Audio resampling\",\n",
    "                       resampled.dtype == np.float32 and np.max(np.abs(resampled)) <= 1.0,\n",
    "                       f\"Output dtype: {resampled.dtype}, max: {np.max(np.abs(resampled)):.3f}\")\n",
    "        \n",
    "        # Test 3: Normalization\n",
    "        normalized = normalize_peak(test_audio, config.peak)\n",
    "        add_test_result(\"Peak normalization\",\n",
    "                       np.max(np.abs(normalized)) <= config.peak + 1e-6,\n",
    "                       f\"Peak: {np.max(np.abs(normalized)):.3f}\")\n",
    "        \n",
    "        # Test 4: Mixture creation\n",
    "        mixture, metadata = make_mixture(stems)\n",
    "        add_test_result(\"Mixture creation\",\n",
    "                       mixture.shape == stems['vocals'].shape and 'mixture_peak_final' in metadata,\n",
    "                       f\"Shape: {mixture.shape}\")\n",
    "        \n",
    "        # Test 5: Chunking\n",
    "        chunks = chunk_waveform(mixture, config.chunk_len, config.sample_rate)\n",
    "        expected_chunk_samples = int(config.chunk_len * config.sample_rate)\n",
    "        add_test_result(\"Audio chunking\",\n",
    "                       len(chunks) > 0 and chunks[0][0].shape[0] == expected_chunk_samples,\n",
    "                       f\"Created {len(chunks)} chunks\")\n",
    "        \n",
    "        # Test 6: STFT computation\n",
    "        test_chunk = chunks[0][0]\n",
    "        if test_chunk.ndim > 1:\n",
    "            test_chunk = test_chunk[:, 0]\n",
    "        complex_spec = compute_stft(test_chunk, config.n_fft, config.hop_length)\n",
    "        mag, phase = magnitude_phase_from_complex(complex_spec)\n",
    "        add_test_result(\"STFT computation\",\n",
    "                       complex_spec.shape[0] == config.n_fft // 2 + 1,\n",
    "                       f\"Spec shape: {complex_spec.shape}\")\n",
    "        \n",
    "        # Test 7: IRM computation\n",
    "        # Create dummy source spectrograms\n",
    "        dummy_sources = [mag * 0.5, mag * 0.3, mag * 0.2, mag * 0.1]\n",
    "        irm_masks = compute_irm_masks(dummy_sources, mag)\n",
    "        all_in_range = all(np.all((mask >= 0) & (mask <= 1)) for mask in irm_masks)\n",
    "        add_test_result(\"IRM mask computation\",\n",
    "                       len(irm_masks) == len(dummy_sources) and all_in_range,\n",
    "                       f\"Created {len(irm_masks)} masks, all in [0,1]: {all_in_range}\")\n",
    "        \n",
    "        # Test 8: Band splitting\n",
    "        bands = split_bands(mag, config.sample_rate, config.n_fft, config.band_edges_hz)\n",
    "        add_test_result(\"Band splitting\",\n",
    "                       len(bands) == len(config.band_edges_hz) - 1,\n",
    "                       f\"Created {len(bands)} bands\")\n",
    "        \n",
    "        # Test 9: Validation function\n",
    "        test_fields = {\n",
    "            'mixture_wav': test_chunk,\n",
    "            'irm_masks': irm_masks,\n",
    "            'mag': mag\n",
    "        }\n",
    "        warnings = validate_chunk_fields(test_fields)\n",
    "        add_test_result(\"Field validation\",\n",
    "                       isinstance(warnings, list),\n",
    "                       f\"Validation returned {len(warnings)} warnings\")\n",
    "        \n",
    "        # Test 10: Oracle reconstruction\n",
    "        reconstructed = reconstruct_from_mask(complex_spec, irm_masks[0])\n",
    "        add_test_result(\"Oracle reconstruction\",\n",
    "                       reconstructed.shape[0] > 0 and np.isfinite(reconstructed).all(),\n",
    "                       f\"Reconstructed shape: {reconstructed.shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        add_test_result(\"Unit tests execution\", False, f\"Error: {str(e)}\")\n",
    "    \n",
    "    print(f\"\\nUnit test summary: {test_results['passed']} passed, {test_results['failed']} failed\")\n",
    "    return test_results\n",
    "\n",
    "# Run unit tests\n",
    "unit_test_results = run_unit_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac456c7",
   "metadata": {},
   "source": [
    "## Batch Preprocessing: Complete MUSDB18 Dataset\n",
    "\n",
    "Both train and test sets will undergo the same preprocessing pipeline to ensure consistency. The only difference is that they'll be saved to separate directories to maintain the train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d5f96ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch preprocessing functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Enhanced batch preprocessing with progress tracking and error handling\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def preprocess_dataset_subset(tracks, subset_name, config, base_output_dir, apply_augmentations=False):\n",
    "    \"\"\"\n",
    "    Preprocess a subset (train or test) of the MUSDB18 dataset.\n",
    "    \n",
    "    Args:\n",
    "        tracks: list of musdb.Track objects\n",
    "        subset_name: 'train' or 'test'\n",
    "        config: PreprocessingConfig object\n",
    "        base_output_dir: base output directory\n",
    "        apply_augmentations: whether to apply data augmentations\n",
    "        \n",
    "    Returns:\n",
    "        subset_summary: dict with detailed statistics\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing {subset_name.upper()} set: {len(tracks)} tracks\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create subset-specific output directory\n",
    "    subset_output_dir = Path(base_output_dir) / subset_name\n",
    "    subset_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Track processing statistics\n",
    "    subset_summary = {\n",
    "        'subset_name': subset_name,\n",
    "        'total_tracks': len(tracks),\n",
    "        'processed_tracks': 0,\n",
    "        'failed_tracks': 0,\n",
    "        'total_chunks': 0,\n",
    "        'processed_chunks': 0,\n",
    "        'failed_chunks': 0,\n",
    "        'processing_time_seconds': 0,\n",
    "        'track_summaries': [],\n",
    "        'failed_track_names': [],\n",
    "        'warnings': []\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Process each track with progress bar\n",
    "    for track in tqdm(tracks, desc=f\"Processing {subset_name} tracks\"):\n",
    "        try:\n",
    "            track_summary = preprocess_track(\n",
    "                track, \n",
    "                config, \n",
    "                subset_output_dir,\n",
    "                apply_augmentations=apply_augmentations,\n",
    "                augmentation_seed=42  # Fixed seed for reproducibility\n",
    "            )\n",
    "            \n",
    "            # Update statistics\n",
    "            subset_summary['processed_tracks'] += 1\n",
    "            subset_summary['total_chunks'] += track_summary['total_chunks']\n",
    "            subset_summary['processed_chunks'] += track_summary['processed_chunks']\n",
    "            subset_summary['failed_chunks'] += track_summary['failed_chunks']\n",
    "            subset_summary['track_summaries'].append(track_summary)\n",
    "            subset_summary['warnings'].extend(track_summary['warnings'])\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nFATAL ERROR processing track '{track.name}': {str(e)}\")\n",
    "            subset_summary['failed_tracks'] += 1\n",
    "            subset_summary['failed_track_names'].append(track.name)\n",
    "            subset_summary['warnings'].append(f\"FATAL: {track.name} - {str(e)}\")\n",
    "    \n",
    "    subset_summary['processing_time_seconds'] = time.time() - start_time\n",
    "    \n",
    "    # Print subset summary\n",
    "    print(f\"\\n{subset_name.upper()} SET SUMMARY:\")\n",
    "    print(f\"Tracks processed: {subset_summary['processed_tracks']}/{subset_summary['total_tracks']}\")\n",
    "    print(f\"Chunks processed: {subset_summary['processed_chunks']}/{subset_summary['total_chunks']}\")\n",
    "    print(f\"Failed tracks: {subset_summary['failed_tracks']}\")\n",
    "    print(f\"Processing time: {subset_summary['processing_time_seconds']:.1f} seconds\")\n",
    "    \n",
    "    if subset_summary['failed_track_names']:\n",
    "        print(f\"Failed tracks: {', '.join(subset_summary['failed_track_names'])}\")\n",
    "    \n",
    "    return subset_summary\n",
    "\n",
    "def save_processing_report(train_summary, test_summary, config, base_output_dir):\n",
    "    \"\"\"\n",
    "    Save a comprehensive processing report.\n",
    "    \n",
    "    Args:\n",
    "        train_summary: training set processing summary\n",
    "        test_summary: test set processing summary\n",
    "        config: preprocessing configuration\n",
    "        base_output_dir: base output directory\n",
    "    \"\"\"\n",
    "    report = {\n",
    "        'processing_date': datetime.now().isoformat(),\n",
    "        'configuration': {\n",
    "            'sample_rate': config.sample_rate,\n",
    "            'chunk_len': config.chunk_len,\n",
    "            'overlap': config.overlap,\n",
    "            'n_fft': config.n_fft,\n",
    "            'hop_length': config.hop_length,\n",
    "            'window': config.window,\n",
    "            'band_edges_hz': config.band_edges_hz,\n",
    "            'target_sources': config.target_sources\n",
    "        },\n",
    "        'train_summary': train_summary,\n",
    "        'test_summary': test_summary,\n",
    "        'overall_summary': {\n",
    "            'total_tracks': train_summary['total_tracks'] + test_summary['total_tracks'],\n",
    "            'processed_tracks': train_summary['processed_tracks'] + test_summary['processed_tracks'],\n",
    "            'failed_tracks': train_summary['failed_tracks'] + test_summary['failed_tracks'],\n",
    "            'total_chunks': train_summary['total_chunks'] + test_summary['total_chunks'],\n",
    "            'processed_chunks': train_summary['processed_chunks'] + test_summary['processed_chunks'],\n",
    "            'failed_chunks': train_summary['failed_chunks'] + test_summary['failed_chunks'],\n",
    "            'total_processing_time': train_summary['processing_time_seconds'] + test_summary['processing_time_seconds']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save report as JSON\n",
    "    report_path = Path(base_output_dir) / 'preprocessing_report.json'\n",
    "    with open(report_path, 'w') as f:\n",
    "        json.dump(report, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nProcessing report saved to: {report_path}\")\n",
    "    return report\n",
    "\n",
    "print(\"Batch preprocessing functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e9a98d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring preprocessing for full MUSDB18 dataset...\n",
      "\n",
      "Current configuration:\n",
      "Sample rate: 44100 Hz\n",
      "Chunk length: 4.0 seconds\n",
      "Overlap: 0.0 (0.0 = no overlap)\n",
      "FFT size: 4096\n",
      "Apply augmentations: False\n",
      "\n",
      "Dataset overview:\n",
      "Train tracks: 94\n",
      "Test tracks: 50\n",
      "Total tracks: 144\n",
      "Estimated chunks: ~12960\n",
      "Estimated disk space per chunk: ~15-20 MB\n",
      "Estimated total disk space: ~221.5 GB\n",
      "\n",
      "Output directory structure:\n",
      "  musdb18_processed/\n",
      "  ├── train/          (training set chunks)\n",
      "  ├── test/           (test set chunks)\n",
      "  └── preprocessing_report.json\n",
      "\n",
      "Ready to start batch processing!\n",
      "Run the next cell to begin processing the entire dataset.\n"
     ]
    }
   ],
   "source": [
    "# Configure preprocessing settings for the full dataset\n",
    "print(\"Configuring preprocessing for full MUSDB18 dataset...\")\n",
    "\n",
    "# Base output directory for all processed data\n",
    "base_output_dir = Path(\"musdb18_processed\")\n",
    "base_output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# You can modify these settings before running the batch processing\n",
    "print(\"\\nCurrent configuration:\")\n",
    "print(f\"Sample rate: {config.sample_rate} Hz\")\n",
    "print(f\"Chunk length: {config.chunk_len} seconds\")\n",
    "print(f\"Overlap: {config.overlap} (0.0 = no overlap)\")\n",
    "print(f\"FFT size: {config.n_fft}\")\n",
    "print(f\"Apply augmentations: {config.enable_random_gain or config.enable_add_noise}\")\n",
    "\n",
    "# Estimate processing requirements\n",
    "total_tracks = len(mus_train) + len(mus_test)\n",
    "avg_track_duration = 6.0  # Average track duration in minutes\n",
    "avg_chunks_per_track = int((avg_track_duration * 60) / config.chunk_len)\n",
    "estimated_total_chunks = total_tracks * avg_chunks_per_track\n",
    "\n",
    "print(f\"\\nDataset overview:\")\n",
    "print(f\"Train tracks: {len(mus_train)}\")\n",
    "print(f\"Test tracks: {len(mus_test)}\")\n",
    "print(f\"Total tracks: {total_tracks}\")\n",
    "print(f\"Estimated chunks: ~{estimated_total_chunks}\")\n",
    "print(f\"Estimated disk space per chunk: ~15-20 MB\")\n",
    "print(f\"Estimated total disk space: ~{estimated_total_chunks * 17.5 / 1024:.1f} GB\")\n",
    "\n",
    "print(f\"\\nOutput directory structure:\")\n",
    "print(f\"  {base_output_dir}/\")\n",
    "print(f\"  ├── train/          (training set chunks)\")\n",
    "print(f\"  ├── test/           (test set chunks)\")\n",
    "print(f\"  └── preprocessing_report.json\")\n",
    "\n",
    "print(\"\\nReady to start batch processing!\")\n",
    "print(\"Run the next cell to begin processing the entire dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b3be8d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " STARTING FULL MUSDB18 DATASET PREPROCESSING\n",
      "================================================================================\n",
      "PHASE 1: Processing Training Set\n",
      "\n",
      "============================================================\n",
      "Processing TRAIN set: 94 tracks\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:   0%|          | 0/94 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track: A Classic Education - NightOwl\n",
      "Loaded track 'A Classic Education - NightOwl' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.556 to prevent clipping (peak was 1.710)\n",
      "Loaded track 'A Classic Education - NightOwl' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.556 to prevent clipping (peak was 1.710)\n",
      "Saved chunk to musdb18_processed\\train\\A Classic Education - NightOwl_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\A Classic Education - NightOwl_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:   1%|          | 1/94 [00:02<03:45,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\A Classic Education - NightOwl_chunk_001.npz\n",
      "Completed processing A Classic Education - NightOwl: 2 chunks processed, 0 failed\n",
      "Processing track: ANiMAL - Clinic A\n",
      "Loaded track 'ANiMAL - Clinic A' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.455 to prevent clipping (peak was 2.088)\n",
      "Loaded track 'ANiMAL - Clinic A' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.455 to prevent clipping (peak was 2.088)\n",
      "Saved chunk to musdb18_processed\\train\\ANiMAL - Clinic A_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\ANiMAL - Clinic A_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:   2%|▏         | 2/94 [00:04<03:41,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\ANiMAL - Clinic A_chunk_001.npz\n",
      "Completed processing ANiMAL - Clinic A: 2 chunks processed, 0 failed\n",
      "Processing track: ANiMAL - Easy Tiger\n",
      "Loaded track 'ANiMAL - Easy Tiger' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.522 to prevent clipping (peak was 1.819)\n",
      "Loaded track 'ANiMAL - Easy Tiger' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.522 to prevent clipping (peak was 1.819)\n",
      "Saved chunk to musdb18_processed\\train\\ANiMAL - Easy Tiger_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\ANiMAL - Easy Tiger_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:   3%|▎         | 3/94 [00:07<03:41,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\ANiMAL - Easy Tiger_chunk_001.npz\n",
      "Completed processing ANiMAL - Easy Tiger: 2 chunks processed, 0 failed\n",
      "Processing track: ANiMAL - Rockshow\n",
      "Loaded track 'ANiMAL - Rockshow' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.503 to prevent clipping (peak was 1.890)\n",
      "Loaded track 'ANiMAL - Rockshow' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.503 to prevent clipping (peak was 1.890)\n",
      "Saved chunk to musdb18_processed\\train\\ANiMAL - Rockshow_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\ANiMAL - Rockshow_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:   4%|▍         | 4/94 [00:09<03:38,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\ANiMAL - Rockshow_chunk_001.npz\n",
      "Completed processing ANiMAL - Rockshow: 2 chunks processed, 0 failed\n",
      "Processing track: Actions - Devil's Words\n",
      "Loaded track 'Actions - Devil's Words' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.491 to prevent clipping (peak was 1.935)\n",
      "Loaded track 'Actions - Devil's Words' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.491 to prevent clipping (peak was 1.935)\n",
      "Saved chunk to musdb18_processed\\train\\Actions - Devil's Words_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Actions - Devil's Words_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:   5%|▌         | 5/94 [00:11<03:31,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Actions - Devil's Words_chunk_001.npz\n",
      "Completed processing Actions - Devil's Words: 2 chunks processed, 0 failed\n",
      "Processing track: Actions - One Minute Smile\n",
      "Loaded track 'Actions - One Minute Smile' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.453 to prevent clipping (peak was 2.097)\n",
      "Loaded track 'Actions - One Minute Smile' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.453 to prevent clipping (peak was 2.097)\n",
      "Saved chunk to musdb18_processed\\train\\Actions - One Minute Smile_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Actions - One Minute Smile_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:   6%|▋         | 6/94 [00:14<03:27,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Actions - One Minute Smile_chunk_001.npz\n",
      "Completed processing Actions - One Minute Smile: 2 chunks processed, 0 failed\n",
      "Processing track: Actions - South Of The Water\n",
      "Loaded track 'Actions - South Of The Water' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.447 to prevent clipping (peak was 2.127)\n",
      "Loaded track 'Actions - South Of The Water' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.447 to prevent clipping (peak was 2.127)\n",
      "Saved chunk to musdb18_processed\\train\\Actions - South Of The Water_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Actions - South Of The Water_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:   7%|▋         | 7/94 [00:16<03:27,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Actions - South Of The Water_chunk_001.npz\n",
      "Completed processing Actions - South Of The Water: 2 chunks processed, 0 failed\n",
      "Processing track: Aimee Norwich - Child\n",
      "Loaded track 'Aimee Norwich - Child' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.469 to prevent clipping (peak was 2.027)\n",
      "Loaded track 'Aimee Norwich - Child' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.469 to prevent clipping (peak was 2.027)\n",
      "Saved chunk to musdb18_processed\\train\\Aimee Norwich - Child_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Aimee Norwich - Child_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:   9%|▊         | 8/94 [00:19<03:27,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Aimee Norwich - Child_chunk_001.npz\n",
      "Completed processing Aimee Norwich - Child: 2 chunks processed, 0 failed\n",
      "Processing track: Alexander Ross - Goodbye Bolero\n",
      "Loaded track 'Alexander Ross - Goodbye Bolero' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.467 to prevent clipping (peak was 2.034)\n",
      "Loaded track 'Alexander Ross - Goodbye Bolero' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.467 to prevent clipping (peak was 2.034)\n",
      "Saved chunk to musdb18_processed\\train\\Alexander Ross - Goodbye Bolero_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Alexander Ross - Goodbye Bolero_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  10%|▉         | 9/94 [00:21<03:22,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Alexander Ross - Goodbye Bolero_chunk_001.npz\n",
      "Completed processing Alexander Ross - Goodbye Bolero: 2 chunks processed, 0 failed\n",
      "Processing track: Alexander Ross - Velvet Curtain\n",
      "Loaded track 'Alexander Ross - Velvet Curtain' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.435 to prevent clipping (peak was 2.183)\n",
      "Loaded track 'Alexander Ross - Velvet Curtain' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.435 to prevent clipping (peak was 2.183)\n",
      "Saved chunk to musdb18_processed\\train\\Alexander Ross - Velvet Curtain_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Alexander Ross - Velvet Curtain_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  11%|█         | 10/94 [00:23<03:18,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Alexander Ross - Velvet Curtain_chunk_001.npz\n",
      "Completed processing Alexander Ross - Velvet Curtain: 2 chunks processed, 0 failed\n",
      "Processing track: Angela Thomas Wade - Milk Cow Blues\n",
      "Loaded track 'Angela Thomas Wade - Milk Cow Blues' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.539 to prevent clipping (peak was 1.762)\n",
      "Loaded track 'Angela Thomas Wade - Milk Cow Blues' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.539 to prevent clipping (peak was 1.762)\n",
      "Saved chunk to musdb18_processed\\train\\Angela Thomas Wade - Milk Cow Blues_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Angela Thomas Wade - Milk Cow Blues_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  12%|█▏        | 11/94 [00:26<03:18,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Angela Thomas Wade - Milk Cow Blues_chunk_001.npz\n",
      "Completed processing Angela Thomas Wade - Milk Cow Blues: 2 chunks processed, 0 failed\n",
      "Processing track: Atlantis Bound - It Was My Fault For Waiting\n",
      "Loaded track 'Atlantis Bound - It Was My Fault For Waiting' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.478 to prevent clipping (peak was 1.987)\n",
      "Loaded track 'Atlantis Bound - It Was My Fault For Waiting' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.478 to prevent clipping (peak was 1.987)\n",
      "Saved chunk to musdb18_processed\\train\\Atlantis Bound - It Was My Fault For Waiting_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Atlantis Bound - It Was My Fault For Waiting_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  13%|█▎        | 12/94 [00:29<03:34,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Atlantis Bound - It Was My Fault For Waiting_chunk_001.npz\n",
      "Completed processing Atlantis Bound - It Was My Fault For Waiting: 2 chunks processed, 0 failed\n",
      "Processing track: Auctioneer - Our Future Faces\n",
      "Loaded track 'Auctioneer - Our Future Faces' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.436 to prevent clipping (peak was 2.181)\n",
      "Loaded track 'Auctioneer - Our Future Faces' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.436 to prevent clipping (peak was 2.181)\n",
      "Saved chunk to musdb18_processed\\train\\Auctioneer - Our Future Faces_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Auctioneer - Our Future Faces_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  14%|█▍        | 13/94 [00:32<03:50,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Auctioneer - Our Future Faces_chunk_001.npz\n",
      "Completed processing Auctioneer - Our Future Faces: 2 chunks processed, 0 failed\n",
      "Processing track: AvaLuna - Waterduct\n",
      "Loaded track 'AvaLuna - Waterduct' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.421 to prevent clipping (peak was 2.255)\n",
      "Loaded track 'AvaLuna - Waterduct' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.421 to prevent clipping (peak was 2.255)\n",
      "Saved chunk to musdb18_processed\\train\\AvaLuna - Waterduct_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\AvaLuna - Waterduct_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  15%|█▍        | 14/94 [00:35<03:55,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\AvaLuna - Waterduct_chunk_001.npz\n",
      "Completed processing AvaLuna - Waterduct: 2 chunks processed, 0 failed\n",
      "Processing track: BigTroubles - Phantom\n",
      "Loaded track 'BigTroubles - Phantom' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.521 to prevent clipping (peak was 1.824)\n",
      "Loaded track 'BigTroubles - Phantom' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.521 to prevent clipping (peak was 1.824)\n",
      "Saved chunk to musdb18_processed\\train\\BigTroubles - Phantom_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\BigTroubles - Phantom_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  16%|█▌        | 15/94 [00:39<03:58,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\BigTroubles - Phantom_chunk_001.npz\n",
      "Completed processing BigTroubles - Phantom: 2 chunks processed, 0 failed\n",
      "Processing track: Bill Chudziak - Children Of No-one\n",
      "Loaded track 'Bill Chudziak - Children Of No-one' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.516 to prevent clipping (peak was 1.842)\n",
      "Loaded track 'Bill Chudziak - Children Of No-one' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.516 to prevent clipping (peak was 1.842)\n",
      "Saved chunk to musdb18_processed\\train\\Bill Chudziak - Children Of No-one_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Bill Chudziak - Children Of No-one_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  17%|█▋        | 16/94 [00:42<03:59,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Bill Chudziak - Children Of No-one_chunk_001.npz\n",
      "Completed processing Bill Chudziak - Children Of No-one: 2 chunks processed, 0 failed\n",
      "Processing track: Black Bloc - If You Want Success\n",
      "Loaded track 'Black Bloc - If You Want Success' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.454 to prevent clipping (peak was 2.095)\n",
      "Loaded track 'Black Bloc - If You Want Success' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.454 to prevent clipping (peak was 2.095)\n",
      "Saved chunk to musdb18_processed\\train\\Black Bloc - If You Want Success_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Black Bloc - If You Want Success_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  18%|█▊        | 17/94 [00:45<03:57,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Black Bloc - If You Want Success_chunk_001.npz\n",
      "Completed processing Black Bloc - If You Want Success: 2 chunks processed, 0 failed\n",
      "Processing track: Celestial Shore - Die For Us\n",
      "Loaded track 'Celestial Shore - Die For Us' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.531 to prevent clipping (peak was 1.789)\n",
      "Loaded track 'Celestial Shore - Die For Us' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.531 to prevent clipping (peak was 1.789)\n",
      "Saved chunk to musdb18_processed\\train\\Celestial Shore - Die For Us_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Celestial Shore - Die For Us_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  19%|█▉        | 18/94 [00:48<03:59,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Celestial Shore - Die For Us_chunk_001.npz\n",
      "Completed processing Celestial Shore - Die For Us: 2 chunks processed, 0 failed\n",
      "Processing track: Chris Durban - Celebrate\n",
      "Loaded track 'Chris Durban - Celebrate' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.514 to prevent clipping (peak was 1.850)\n",
      "Loaded track 'Chris Durban - Celebrate' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.514 to prevent clipping (peak was 1.850)\n",
      "Saved chunk to musdb18_processed\\train\\Chris Durban - Celebrate_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Chris Durban - Celebrate_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  20%|██        | 19/94 [00:51<03:50,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Chris Durban - Celebrate_chunk_001.npz\n",
      "Completed processing Chris Durban - Celebrate: 2 chunks processed, 0 failed\n",
      "Processing track: Clara Berry And Wooldog - Air Traffic\n",
      "Loaded track 'Clara Berry And Wooldog - Air Traffic' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.526 to prevent clipping (peak was 1.806)\n",
      "Loaded track 'Clara Berry And Wooldog - Air Traffic' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.526 to prevent clipping (peak was 1.806)\n",
      "Saved chunk to musdb18_processed\\train\\Clara Berry And Wooldog - Air Traffic_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Clara Berry And Wooldog - Air Traffic_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  21%|██▏       | 20/94 [00:54<03:34,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Clara Berry And Wooldog - Air Traffic_chunk_001.npz\n",
      "Completed processing Clara Berry And Wooldog - Air Traffic: 2 chunks processed, 0 failed\n",
      "Processing track: Clara Berry And Wooldog - Stella\n",
      "Loaded track 'Clara Berry And Wooldog - Stella' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.460 to prevent clipping (peak was 2.063)\n",
      "Loaded track 'Clara Berry And Wooldog - Stella' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.460 to prevent clipping (peak was 2.063)\n",
      "Saved chunk to musdb18_processed\\train\\Clara Berry And Wooldog - Stella_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Clara Berry And Wooldog - Stella_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  22%|██▏       | 21/94 [00:56<03:21,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Clara Berry And Wooldog - Stella_chunk_001.npz\n",
      "Completed processing Clara Berry And Wooldog - Stella: 2 chunks processed, 0 failed\n",
      "Processing track: Clara Berry And Wooldog - Waltz For My Victims\n",
      "Loaded track 'Clara Berry And Wooldog - Waltz For My Victims' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.381 to prevent clipping (peak was 2.494)\n",
      "Loaded track 'Clara Berry And Wooldog - Waltz For My Victims' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.381 to prevent clipping (peak was 2.494)\n",
      "Saved chunk to musdb18_processed\\train\\Clara Berry And Wooldog - Waltz For My Victims_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Clara Berry And Wooldog - Waltz For My Victims_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  23%|██▎       | 22/94 [00:59<03:11,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Clara Berry And Wooldog - Waltz For My Victims_chunk_001.npz\n",
      "Completed processing Clara Berry And Wooldog - Waltz For My Victims: 2 chunks processed, 0 failed\n",
      "Processing track: Cnoc An Tursa - Bannockburn\n",
      "Loaded track 'Cnoc An Tursa - Bannockburn' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.490 to prevent clipping (peak was 1.938)\n",
      "Loaded track 'Cnoc An Tursa - Bannockburn' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.490 to prevent clipping (peak was 1.938)\n",
      "Saved chunk to musdb18_processed\\train\\Cnoc An Tursa - Bannockburn_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Cnoc An Tursa - Bannockburn_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  24%|██▍       | 23/94 [01:01<03:01,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Cnoc An Tursa - Bannockburn_chunk_001.npz\n",
      "Completed processing Cnoc An Tursa - Bannockburn: 2 chunks processed, 0 failed\n",
      "Processing track: Creepoid - OldTree\n",
      "Loaded track 'Creepoid - OldTree' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.402 to prevent clipping (peak was 2.366)\n",
      "Loaded track 'Creepoid - OldTree' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.402 to prevent clipping (peak was 2.366)\n",
      "Saved chunk to musdb18_processed\\train\\Creepoid - OldTree_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Creepoid - OldTree_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  26%|██▌       | 24/94 [01:04<03:06,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Creepoid - OldTree_chunk_001.npz\n",
      "Completed processing Creepoid - OldTree: 2 chunks processed, 0 failed\n",
      "Processing track: Dark Ride - Burning Bridges\n",
      "Loaded track 'Dark Ride - Burning Bridges' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.397 to prevent clipping (peak was 2.391)\n",
      "Loaded track 'Dark Ride - Burning Bridges' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.397 to prevent clipping (peak was 2.391)\n",
      "Saved chunk to musdb18_processed\\train\\Dark Ride - Burning Bridges_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Dark Ride - Burning Bridges_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  27%|██▋       | 25/94 [01:07<03:12,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Dark Ride - Burning Bridges_chunk_001.npz\n",
      "Completed processing Dark Ride - Burning Bridges: 2 chunks processed, 0 failed\n",
      "Processing track: Dreamers Of The Ghetto - Heavy Love\n",
      "Loaded track 'Dreamers Of The Ghetto - Heavy Love' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.499 to prevent clipping (peak was 1.902)\n",
      "Loaded track 'Dreamers Of The Ghetto - Heavy Love' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.499 to prevent clipping (peak was 1.902)\n",
      "Saved chunk to musdb18_processed\\train\\Dreamers Of The Ghetto - Heavy Love_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Dreamers Of The Ghetto - Heavy Love_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  28%|██▊       | 26/94 [01:10<03:16,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Dreamers Of The Ghetto - Heavy Love_chunk_001.npz\n",
      "Completed processing Dreamers Of The Ghetto - Heavy Love: 2 chunks processed, 0 failed\n",
      "Processing track: Drumtracks - Ghost Bitch\n",
      "Loaded track 'Drumtracks - Ghost Bitch' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.497 to prevent clipping (peak was 1.912)\n",
      "Loaded track 'Drumtracks - Ghost Bitch' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.497 to prevent clipping (peak was 1.912)\n",
      "Saved chunk to musdb18_processed\\train\\Drumtracks - Ghost Bitch_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Drumtracks - Ghost Bitch_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  29%|██▊       | 27/94 [01:13<03:17,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Drumtracks - Ghost Bitch_chunk_001.npz\n",
      "Completed processing Drumtracks - Ghost Bitch: 2 chunks processed, 0 failed\n",
      "Processing track: Faces On Film - Waiting For Ga\n",
      "Loaded track 'Faces On Film - Waiting For Ga' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.430 to prevent clipping (peak was 2.209)\n",
      "Loaded track 'Faces On Film - Waiting For Ga' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.430 to prevent clipping (peak was 2.209)\n",
      "Saved chunk to musdb18_processed\\train\\Faces On Film - Waiting For Ga_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Faces On Film - Waiting For Ga_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  30%|██▉       | 28/94 [01:16<03:17,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Faces On Film - Waiting For Ga_chunk_001.npz\n",
      "Completed processing Faces On Film - Waiting For Ga: 2 chunks processed, 0 failed\n",
      "Processing track: Fergessen - Back From The Start\n",
      "Loaded track 'Fergessen - Back From The Start' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.474 to prevent clipping (peak was 2.004)\n",
      "Loaded track 'Fergessen - Back From The Start' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.474 to prevent clipping (peak was 2.004)\n",
      "Saved chunk to musdb18_processed\\train\\Fergessen - Back From The Start_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Fergessen - Back From The Start_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  31%|███       | 29/94 [01:19<03:13,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Fergessen - Back From The Start_chunk_001.npz\n",
      "Completed processing Fergessen - Back From The Start: 2 chunks processed, 0 failed\n",
      "Processing track: Fergessen - Nos Palpitants\n",
      "Loaded track 'Fergessen - Nos Palpitants' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.454 to prevent clipping (peak was 2.094)\n",
      "Loaded track 'Fergessen - Nos Palpitants' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.454 to prevent clipping (peak was 2.094)\n",
      "Saved chunk to musdb18_processed\\train\\Fergessen - Nos Palpitants_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Fergessen - Nos Palpitants_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  32%|███▏      | 30/94 [01:22<03:10,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Fergessen - Nos Palpitants_chunk_001.npz\n",
      "Completed processing Fergessen - Nos Palpitants: 2 chunks processed, 0 failed\n",
      "Processing track: Fergessen - The Wind\n",
      "Loaded track 'Fergessen - The Wind' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.485 to prevent clipping (peak was 1.957)\n",
      "Loaded track 'Fergessen - The Wind' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.485 to prevent clipping (peak was 1.957)\n",
      "Saved chunk to musdb18_processed\\train\\Fergessen - The Wind_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Fergessen - The Wind_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  33%|███▎      | 31/94 [01:25<03:07,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Fergessen - The Wind_chunk_001.npz\n",
      "Completed processing Fergessen - The Wind: 2 chunks processed, 0 failed\n",
      "Processing track: Flags - 54\n",
      "Loaded track 'Flags - 54' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.469 to prevent clipping (peak was 2.026)\n",
      "Loaded track 'Flags - 54' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.469 to prevent clipping (peak was 2.026)\n",
      "Saved chunk to musdb18_processed\\train\\Flags - 54_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Flags - 54_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  34%|███▍      | 32/94 [01:28<03:04,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Flags - 54_chunk_001.npz\n",
      "Completed processing Flags - 54: 2 chunks processed, 0 failed\n",
      "Processing track: Giselle - Moss\n",
      "Loaded track 'Giselle - Moss' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.384 to prevent clipping (peak was 2.474)\n",
      "Loaded track 'Giselle - Moss' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.384 to prevent clipping (peak was 2.474)\n",
      "Saved chunk to musdb18_processed\\train\\Giselle - Moss_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Giselle - Moss_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  35%|███▌      | 33/94 [01:31<03:01,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Giselle - Moss_chunk_001.npz\n",
      "Completed processing Giselle - Moss: 2 chunks processed, 0 failed\n",
      "Processing track: Grants - PunchDrunk\n",
      "Loaded track 'Grants - PunchDrunk' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.497 to prevent clipping (peak was 1.911)\n",
      "Loaded track 'Grants - PunchDrunk' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.497 to prevent clipping (peak was 1.911)\n",
      "Saved chunk to musdb18_processed\\train\\Grants - PunchDrunk_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Grants - PunchDrunk_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  36%|███▌      | 34/94 [01:34<03:02,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Grants - PunchDrunk_chunk_001.npz\n",
      "Completed processing Grants - PunchDrunk: 2 chunks processed, 0 failed\n",
      "Processing track: Helado Negro - Mitad Del Mundo\n",
      "Loaded track 'Helado Negro - Mitad Del Mundo' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.431 to prevent clipping (peak was 2.204)\n",
      "Loaded track 'Helado Negro - Mitad Del Mundo' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.431 to prevent clipping (peak was 2.204)\n",
      "Saved chunk to musdb18_processed\\train\\Helado Negro - Mitad Del Mundo_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Helado Negro - Mitad Del Mundo_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  37%|███▋      | 35/94 [01:37<03:02,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Helado Negro - Mitad Del Mundo_chunk_001.npz\n",
      "Completed processing Helado Negro - Mitad Del Mundo: 2 chunks processed, 0 failed\n",
      "Processing track: Hezekiah Jones - Borrowed Heart\n",
      "Loaded track 'Hezekiah Jones - Borrowed Heart' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.496 to prevent clipping (peak was 1.914)\n",
      "Loaded track 'Hezekiah Jones - Borrowed Heart' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.496 to prevent clipping (peak was 1.914)\n",
      "Saved chunk to musdb18_processed\\train\\Hezekiah Jones - Borrowed Heart_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Hezekiah Jones - Borrowed Heart_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  38%|███▊      | 36/94 [01:41<02:59,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Hezekiah Jones - Borrowed Heart_chunk_001.npz\n",
      "Completed processing Hezekiah Jones - Borrowed Heart: 2 chunks processed, 0 failed\n",
      "Processing track: Hollow Ground - Left Blind\n",
      "Loaded track 'Hollow Ground - Left Blind' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.461 to prevent clipping (peak was 2.061)\n",
      "Loaded track 'Hollow Ground - Left Blind' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.461 to prevent clipping (peak was 2.061)\n",
      "Saved chunk to musdb18_processed\\train\\Hollow Ground - Left Blind_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Hollow Ground - Left Blind_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  39%|███▉      | 37/94 [01:43<02:54,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Hollow Ground - Left Blind_chunk_001.npz\n",
      "Completed processing Hollow Ground - Left Blind: 2 chunks processed, 0 failed\n",
      "Processing track: Hop Along - Sister Cities\n",
      "Loaded track 'Hop Along - Sister Cities' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.486 to prevent clipping (peak was 1.956)\n",
      "Loaded track 'Hop Along - Sister Cities' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.486 to prevent clipping (peak was 1.956)\n",
      "Saved chunk to musdb18_processed\\train\\Hop Along - Sister Cities_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Hop Along - Sister Cities_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  40%|████      | 38/94 [01:47<02:51,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Hop Along - Sister Cities_chunk_001.npz\n",
      "Completed processing Hop Along - Sister Cities: 2 chunks processed, 0 failed\n",
      "Processing track: Invisible Familiars - Disturbing Wildlife\n",
      "Loaded track 'Invisible Familiars - Disturbing Wildlife' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.505 to prevent clipping (peak was 1.882)\n",
      "Loaded track 'Invisible Familiars - Disturbing Wildlife' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.505 to prevent clipping (peak was 1.882)\n",
      "Saved chunk to musdb18_processed\\train\\Invisible Familiars - Disturbing Wildlife_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Invisible Familiars - Disturbing Wildlife_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  41%|████▏     | 39/94 [01:50<02:48,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Invisible Familiars - Disturbing Wildlife_chunk_001.npz\n",
      "Completed processing Invisible Familiars - Disturbing Wildlife: 2 chunks processed, 0 failed\n",
      "Processing track: James May - All Souls Moon\n",
      "Loaded track 'James May - All Souls Moon' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.491 to prevent clipping (peak was 1.935)\n",
      "Loaded track 'James May - All Souls Moon' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.491 to prevent clipping (peak was 1.935)\n",
      "Saved chunk to musdb18_processed\\train\\James May - All Souls Moon_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\James May - All Souls Moon_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  43%|████▎     | 40/94 [01:53<02:45,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\James May - All Souls Moon_chunk_001.npz\n",
      "Completed processing James May - All Souls Moon: 2 chunks processed, 0 failed\n",
      "Processing track: James May - Dont Let Go\n",
      "Loaded track 'James May - Dont Let Go' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.593 to prevent clipping (peak was 1.602)\n",
      "Loaded track 'James May - Dont Let Go' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.593 to prevent clipping (peak was 1.602)\n",
      "Saved chunk to musdb18_processed\\train\\James May - Dont Let Go_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\James May - Dont Let Go_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  44%|████▎     | 41/94 [01:56<02:41,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\James May - Dont Let Go_chunk_001.npz\n",
      "Completed processing James May - Dont Let Go: 2 chunks processed, 0 failed\n",
      "Processing track: James May - If You Say\n",
      "Loaded track 'James May - If You Say' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.445 to prevent clipping (peak was 2.134)\n",
      "Loaded track 'James May - If You Say' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.445 to prevent clipping (peak was 2.134)\n",
      "Saved chunk to musdb18_processed\\train\\James May - If You Say_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\James May - If You Say_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  45%|████▍     | 42/94 [01:59<02:41,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\James May - If You Say_chunk_001.npz\n",
      "Completed processing James May - If You Say: 2 chunks processed, 0 failed\n",
      "Processing track: James May - On The Line\n",
      "Loaded track 'James May - On The Line' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.487 to prevent clipping (peak was 1.949)\n",
      "Loaded track 'James May - On The Line' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.487 to prevent clipping (peak was 1.949)\n",
      "Saved chunk to musdb18_processed\\train\\James May - On The Line_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\James May - On The Line_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  46%|████▌     | 43/94 [02:02<02:37,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\James May - On The Line_chunk_001.npz\n",
      "Completed processing James May - On The Line: 2 chunks processed, 0 failed\n",
      "Processing track: Jay Menon - Through My Eyes\n",
      "Loaded track 'Jay Menon - Through My Eyes' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.420 to prevent clipping (peak was 2.261)\n",
      "Loaded track 'Jay Menon - Through My Eyes' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.420 to prevent clipping (peak was 2.261)\n",
      "Saved chunk to musdb18_processed\\train\\Jay Menon - Through My Eyes_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Jay Menon - Through My Eyes_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  47%|████▋     | 44/94 [02:05<02:35,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Jay Menon - Through My Eyes_chunk_001.npz\n",
      "Completed processing Jay Menon - Through My Eyes: 2 chunks processed, 0 failed\n",
      "Processing track: Johnny Lokke - Promises & Lies\n",
      "Loaded track 'Johnny Lokke - Promises & Lies' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.436 to prevent clipping (peak was 2.181)\n",
      "Loaded track 'Johnny Lokke - Promises & Lies' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.436 to prevent clipping (peak was 2.181)\n",
      "Saved chunk to musdb18_processed\\train\\Johnny Lokke - Promises & Lies_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Johnny Lokke - Promises & Lies_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  48%|████▊     | 45/94 [02:08<02:32,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Johnny Lokke - Promises & Lies_chunk_001.npz\n",
      "Completed processing Johnny Lokke - Promises & Lies: 2 chunks processed, 0 failed\n",
      "Processing track: Johnny Lokke - Whisper To A Scream\n",
      "Loaded track 'Johnny Lokke - Whisper To A Scream' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.451 to prevent clipping (peak was 2.109)\n",
      "Loaded track 'Johnny Lokke - Whisper To A Scream' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.451 to prevent clipping (peak was 2.109)\n",
      "Saved chunk to musdb18_processed\\train\\Johnny Lokke - Whisper To A Scream_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Johnny Lokke - Whisper To A Scream_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  49%|████▉     | 46/94 [02:11<02:30,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Johnny Lokke - Whisper To A Scream_chunk_001.npz\n",
      "Completed processing Johnny Lokke - Whisper To A Scream: 2 chunks processed, 0 failed\n",
      "Processing track: Jokers, Jacks & Kings - Sea Of Leaves\n",
      "Loaded track 'Jokers, Jacks & Kings - Sea Of Leaves' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.420 to prevent clipping (peak was 2.264)\n",
      "Loaded track 'Jokers, Jacks & Kings - Sea Of Leaves' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.420 to prevent clipping (peak was 2.264)\n",
      "Saved chunk to musdb18_processed\\train\\Jokers, Jacks & Kings - Sea Of Leaves_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Jokers, Jacks & Kings - Sea Of Leaves_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  50%|█████     | 47/94 [02:15<02:27,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Jokers, Jacks & Kings - Sea Of Leaves_chunk_001.npz\n",
      "Completed processing Jokers, Jacks & Kings - Sea Of Leaves: 2 chunks processed, 0 failed\n",
      "Processing track: Leaf - Come Around\n",
      "Loaded track 'Leaf - Come Around' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.518 to prevent clipping (peak was 1.836)\n",
      "Loaded track 'Leaf - Come Around' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.518 to prevent clipping (peak was 1.836)\n",
      "Saved chunk to musdb18_processed\\train\\Leaf - Come Around_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Leaf - Come Around_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  51%|█████     | 48/94 [02:18<02:25,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Leaf - Come Around_chunk_001.npz\n",
      "Completed processing Leaf - Come Around: 2 chunks processed, 0 failed\n",
      "Processing track: Leaf - Summerghost\n",
      "Loaded track 'Leaf - Summerghost' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.466 to prevent clipping (peak was 2.038)\n",
      "Loaded track 'Leaf - Summerghost' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.466 to prevent clipping (peak was 2.038)\n",
      "Saved chunk to musdb18_processed\\train\\Leaf - Summerghost_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Leaf - Summerghost_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  52%|█████▏    | 49/94 [02:21<02:22,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Leaf - Summerghost_chunk_001.npz\n",
      "Completed processing Leaf - Summerghost: 2 chunks processed, 0 failed\n",
      "Processing track: Leaf - Wicked\n",
      "Loaded track 'Leaf - Wicked' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.459 to prevent clipping (peak was 2.068)\n",
      "Loaded track 'Leaf - Wicked' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.459 to prevent clipping (peak was 2.068)\n",
      "Saved chunk to musdb18_processed\\train\\Leaf - Wicked_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Leaf - Wicked_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  53%|█████▎    | 50/94 [02:24<02:22,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Leaf - Wicked_chunk_001.npz\n",
      "Completed processing Leaf - Wicked: 2 chunks processed, 0 failed\n",
      "Processing track: Lushlife - Toynbee Suite\n",
      "Loaded track 'Lushlife - Toynbee Suite' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.389 to prevent clipping (peak was 2.442)\n",
      "Loaded track 'Lushlife - Toynbee Suite' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.389 to prevent clipping (peak was 2.442)\n",
      "Saved chunk to musdb18_processed\\train\\Lushlife - Toynbee Suite_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Lushlife - Toynbee Suite_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  54%|█████▍    | 51/94 [02:27<02:16,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Lushlife - Toynbee Suite_chunk_001.npz\n",
      "Completed processing Lushlife - Toynbee Suite: 2 chunks processed, 0 failed\n",
      "Processing track: Matthew Entwistle - Dont You Ever\n",
      "Loaded track 'Matthew Entwistle - Dont You Ever' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.654 to prevent clipping (peak was 1.453)\n",
      "Loaded track 'Matthew Entwistle - Dont You Ever' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.654 to prevent clipping (peak was 1.453)\n",
      "Saved chunk to musdb18_processed\\train\\Matthew Entwistle - Dont You Ever_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Matthew Entwistle - Dont You Ever_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  55%|█████▌    | 52/94 [02:30<02:12,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Matthew Entwistle - Dont You Ever_chunk_001.npz\n",
      "Completed processing Matthew Entwistle - Dont You Ever: 2 chunks processed, 0 failed\n",
      "Processing track: Meaxic - Take A Step\n",
      "Loaded track 'Meaxic - Take A Step' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.503 to prevent clipping (peak was 1.888)\n",
      "Loaded track 'Meaxic - Take A Step' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.503 to prevent clipping (peak was 1.888)\n",
      "Saved chunk to musdb18_processed\\train\\Meaxic - Take A Step_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Meaxic - Take A Step_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  56%|█████▋    | 53/94 [02:34<02:08,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Meaxic - Take A Step_chunk_001.npz\n",
      "Completed processing Meaxic - Take A Step: 2 chunks processed, 0 failed\n",
      "Processing track: Meaxic - You Listen\n",
      "Loaded track 'Meaxic - You Listen' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.455 to prevent clipping (peak was 2.089)\n",
      "Loaded track 'Meaxic - You Listen' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.455 to prevent clipping (peak was 2.089)\n",
      "Saved chunk to musdb18_processed\\train\\Meaxic - You Listen_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Meaxic - You Listen_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  57%|█████▋    | 54/94 [02:37<02:06,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Meaxic - You Listen_chunk_001.npz\n",
      "Completed processing Meaxic - You Listen: 2 chunks processed, 0 failed\n",
      "Processing track: Music Delta - 80s Rock\n",
      "Loaded track 'Music Delta - 80s Rock' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.432 to prevent clipping (peak was 2.200)\n",
      "Loaded track 'Music Delta - 80s Rock' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.432 to prevent clipping (peak was 2.200)\n",
      "Saved chunk to musdb18_processed\\train\\Music Delta - 80s Rock_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Music Delta - 80s Rock_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  59%|█████▊    | 55/94 [02:40<02:04,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Music Delta - 80s Rock_chunk_001.npz\n",
      "Completed processing Music Delta - 80s Rock: 2 chunks processed, 0 failed\n",
      "Processing track: Music Delta - Beatles\n",
      "Loaded track 'Music Delta - Beatles' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.467 to prevent clipping (peak was 2.033)\n",
      "Loaded track 'Music Delta - Beatles' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.467 to prevent clipping (peak was 2.033)\n",
      "Saved chunk to musdb18_processed\\train\\Music Delta - Beatles_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Music Delta - Beatles_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  60%|█████▉    | 56/94 [02:43<01:58,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Music Delta - Beatles_chunk_001.npz\n",
      "Completed processing Music Delta - Beatles: 2 chunks processed, 0 failed\n",
      "Processing track: Music Delta - Britpop\n",
      "Loaded track 'Music Delta - Britpop' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.429 to prevent clipping (peak was 2.214)\n",
      "Loaded track 'Music Delta - Britpop' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.429 to prevent clipping (peak was 2.214)\n",
      "Saved chunk to musdb18_processed\\train\\Music Delta - Britpop_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Music Delta - Britpop_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  61%|██████    | 57/94 [02:46<01:54,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Music Delta - Britpop_chunk_001.npz\n",
      "Completed processing Music Delta - Britpop: 2 chunks processed, 0 failed\n",
      "Processing track: Music Delta - Country1\n",
      "Loaded track 'Music Delta - Country1' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.414 to prevent clipping (peak was 2.296)\n",
      "Loaded track 'Music Delta - Country1' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.414 to prevent clipping (peak was 2.296)\n",
      "Saved chunk to musdb18_processed\\train\\Music Delta - Country1_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Music Delta - Country1_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  62%|██████▏   | 58/94 [02:49<01:51,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Music Delta - Country1_chunk_001.npz\n",
      "Completed processing Music Delta - Country1: 2 chunks processed, 0 failed\n",
      "Processing track: Music Delta - Disco\n",
      "Loaded track 'Music Delta - Disco' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.502 to prevent clipping (peak was 1.892)\n",
      "Loaded track 'Music Delta - Disco' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.502 to prevent clipping (peak was 1.892)\n",
      "Saved chunk to musdb18_processed\\train\\Music Delta - Disco_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Music Delta - Disco_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  63%|██████▎   | 59/94 [02:52<01:48,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Music Delta - Disco_chunk_001.npz\n",
      "Completed processing Music Delta - Disco: 2 chunks processed, 0 failed\n",
      "Processing track: Music Delta - Gospel\n",
      "Loaded track 'Music Delta - Gospel' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.448 to prevent clipping (peak was 2.120)\n",
      "Loaded track 'Music Delta - Gospel' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.448 to prevent clipping (peak was 2.120)\n",
      "Saved chunk to musdb18_processed\\train\\Music Delta - Gospel_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Music Delta - Gospel_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  64%|██████▍   | 60/94 [02:55<01:46,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Music Delta - Gospel_chunk_001.npz\n",
      "Completed processing Music Delta - Gospel: 2 chunks processed, 0 failed\n",
      "Processing track: Music Delta - Grunge\n",
      "Loaded track 'Music Delta - Grunge' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.461 to prevent clipping (peak was 2.062)\n",
      "Loaded track 'Music Delta - Grunge' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.461 to prevent clipping (peak was 2.062)\n",
      "Saved chunk to musdb18_processed\\train\\Music Delta - Grunge_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Music Delta - Grunge_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  65%|██████▍   | 61/94 [02:59<01:43,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Music Delta - Grunge_chunk_001.npz\n",
      "Completed processing Music Delta - Grunge: 2 chunks processed, 0 failed\n",
      "Processing track: Night Panther - Fire\n",
      "Loaded track 'Night Panther - Fire' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.472 to prevent clipping (peak was 2.014)\n",
      "Loaded track 'Night Panther - Fire' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.472 to prevent clipping (peak was 2.014)\n",
      "Saved chunk to musdb18_processed\\train\\Night Panther - Fire_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Night Panther - Fire_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  66%|██████▌   | 62/94 [03:02<01:40,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Night Panther - Fire_chunk_001.npz\n",
      "Completed processing Night Panther - Fire: 2 chunks processed, 0 failed\n",
      "Processing track: North To Alaska - All The Same\n",
      "Loaded track 'North To Alaska - All The Same' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.472 to prevent clipping (peak was 2.012)\n",
      "Loaded track 'North To Alaska - All The Same' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.472 to prevent clipping (peak was 2.012)\n",
      "Saved chunk to musdb18_processed\\train\\North To Alaska - All The Same_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\North To Alaska - All The Same_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  67%|██████▋   | 63/94 [03:05<01:36,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\North To Alaska - All The Same_chunk_001.npz\n",
      "Completed processing North To Alaska - All The Same: 2 chunks processed, 0 failed\n",
      "Processing track: Patrick Talbot - A Reason To Leave\n",
      "Loaded track 'Patrick Talbot - A Reason To Leave' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.599 to prevent clipping (peak was 1.587)\n",
      "Loaded track 'Patrick Talbot - A Reason To Leave' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.599 to prevent clipping (peak was 1.587)\n",
      "Saved chunk to musdb18_processed\\train\\Patrick Talbot - A Reason To Leave_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Patrick Talbot - A Reason To Leave_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  68%|██████▊   | 64/94 [03:08<01:33,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Patrick Talbot - A Reason To Leave_chunk_001.npz\n",
      "Completed processing Patrick Talbot - A Reason To Leave: 2 chunks processed, 0 failed\n",
      "Processing track: Patrick Talbot - Set Me Free\n",
      "Loaded track 'Patrick Talbot - Set Me Free' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.467 to prevent clipping (peak was 2.036)\n",
      "Loaded track 'Patrick Talbot - Set Me Free' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.467 to prevent clipping (peak was 2.036)\n",
      "Saved chunk to musdb18_processed\\train\\Patrick Talbot - Set Me Free_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Patrick Talbot - Set Me Free_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  69%|██████▉   | 65/94 [03:11<01:31,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Patrick Talbot - Set Me Free_chunk_001.npz\n",
      "Completed processing Patrick Talbot - Set Me Free: 2 chunks processed, 0 failed\n",
      "Processing track: Phre The Eon - Everybody's Falling Apart\n",
      "Loaded track 'Phre The Eon - Everybody's Falling Apart' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.492 to prevent clipping (peak was 1.930)\n",
      "Loaded track 'Phre The Eon - Everybody's Falling Apart' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.492 to prevent clipping (peak was 1.930)\n",
      "Saved chunk to musdb18_processed\\train\\Phre The Eon - Everybody's Falling Apart_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Phre The Eon - Everybody's Falling Apart_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  70%|███████   | 66/94 [03:14<01:28,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Phre The Eon - Everybody's Falling Apart_chunk_001.npz\n",
      "Completed processing Phre The Eon - Everybody's Falling Apart: 2 chunks processed, 0 failed\n",
      "Processing track: Port St Willow - Stay Even\n",
      "Loaded track 'Port St Willow - Stay Even' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.454 to prevent clipping (peak was 2.093)\n",
      "Loaded track 'Port St Willow - Stay Even' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.454 to prevent clipping (peak was 2.093)\n",
      "Saved chunk to musdb18_processed\\train\\Port St Willow - Stay Even_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Port St Willow - Stay Even_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  71%|███████▏  | 67/94 [03:18<01:25,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Port St Willow - Stay Even_chunk_001.npz\n",
      "Completed processing Port St Willow - Stay Even: 2 chunks processed, 0 failed\n",
      "Processing track: Remember December - C U Next Time\n",
      "Loaded track 'Remember December - C U Next Time' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.455 to prevent clipping (peak was 2.086)\n",
      "Loaded track 'Remember December - C U Next Time' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.455 to prevent clipping (peak was 2.086)\n",
      "Saved chunk to musdb18_processed\\train\\Remember December - C U Next Time_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Remember December - C U Next Time_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  72%|███████▏  | 68/94 [03:21<01:21,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Remember December - C U Next Time_chunk_001.npz\n",
      "Completed processing Remember December - C U Next Time: 2 chunks processed, 0 failed\n",
      "Processing track: Secret Mountains - High Horse\n",
      "Loaded track 'Secret Mountains - High Horse' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.517 to prevent clipping (peak was 1.838)\n",
      "Loaded track 'Secret Mountains - High Horse' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.517 to prevent clipping (peak was 1.838)\n",
      "Saved chunk to musdb18_processed\\train\\Secret Mountains - High Horse_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Secret Mountains - High Horse_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  73%|███████▎  | 69/94 [03:24<01:18,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Secret Mountains - High Horse_chunk_001.npz\n",
      "Completed processing Secret Mountains - High Horse: 2 chunks processed, 0 failed\n",
      "Processing track: Skelpolu - Human Mistakes\n",
      "Loaded track 'Skelpolu - Human Mistakes' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.326 to prevent clipping (peak was 2.911)\n",
      "Loaded track 'Skelpolu - Human Mistakes' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.326 to prevent clipping (peak was 2.911)\n",
      "Saved chunk to musdb18_processed\\train\\Skelpolu - Human Mistakes_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Skelpolu - Human Mistakes_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  74%|███████▍  | 70/94 [03:27<01:15,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Skelpolu - Human Mistakes_chunk_001.npz\n",
      "Completed processing Skelpolu - Human Mistakes: 2 chunks processed, 0 failed\n",
      "Processing track: Skelpolu - Together Alone\n",
      "Loaded track 'Skelpolu - Together Alone' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.457 to prevent clipping (peak was 2.079)\n",
      "Loaded track 'Skelpolu - Together Alone' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.457 to prevent clipping (peak was 2.079)\n",
      "Saved chunk to musdb18_processed\\train\\Skelpolu - Together Alone_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Skelpolu - Together Alone_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  76%|███████▌  | 71/94 [03:30<01:13,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Skelpolu - Together Alone_chunk_001.npz\n",
      "Completed processing Skelpolu - Together Alone: 2 chunks processed, 0 failed\n",
      "Processing track: Snowmine - Curfews\n",
      "Loaded track 'Snowmine - Curfews' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.508 to prevent clipping (peak was 1.869)\n",
      "Loaded track 'Snowmine - Curfews' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.508 to prevent clipping (peak was 1.869)\n",
      "Saved chunk to musdb18_processed\\train\\Snowmine - Curfews_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Snowmine - Curfews_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  77%|███████▋  | 72/94 [03:34<01:11,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Snowmine - Curfews_chunk_001.npz\n",
      "Completed processing Snowmine - Curfews: 2 chunks processed, 0 failed\n",
      "Processing track: Spike Mullings - Mike's Sulking\n",
      "Loaded track 'Spike Mullings - Mike's Sulking' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.536 to prevent clipping (peak was 1.772)\n",
      "Loaded track 'Spike Mullings - Mike's Sulking' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.536 to prevent clipping (peak was 1.772)\n",
      "Saved chunk to musdb18_processed\\train\\Spike Mullings - Mike's Sulking_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Spike Mullings - Mike's Sulking_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  78%|███████▊  | 73/94 [03:37<01:07,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Spike Mullings - Mike's Sulking_chunk_001.npz\n",
      "Completed processing Spike Mullings - Mike's Sulking: 2 chunks processed, 0 failed\n",
      "Processing track: St Vitus - Word Gets Around\n",
      "Loaded track 'St Vitus - Word Gets Around' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.438 to prevent clipping (peak was 2.167)\n",
      "Loaded track 'St Vitus - Word Gets Around' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.438 to prevent clipping (peak was 2.167)\n",
      "Saved chunk to musdb18_processed\\train\\St Vitus - Word Gets Around_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\St Vitus - Word Gets Around_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  79%|███████▊  | 74/94 [03:40<01:05,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\St Vitus - Word Gets Around_chunk_001.npz\n",
      "Completed processing St Vitus - Word Gets Around: 2 chunks processed, 0 failed\n",
      "Processing track: Steven Clark - Bounty\n",
      "Loaded track 'Steven Clark - Bounty' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.479 to prevent clipping (peak was 1.984)\n",
      "Loaded track 'Steven Clark - Bounty' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.479 to prevent clipping (peak was 1.984)\n",
      "Saved chunk to musdb18_processed\\train\\Steven Clark - Bounty_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Steven Clark - Bounty_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  80%|███████▉  | 75/94 [03:43<01:01,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Steven Clark - Bounty_chunk_001.npz\n",
      "Completed processing Steven Clark - Bounty: 2 chunks processed, 0 failed\n",
      "Processing track: Strand Of Oaks - Spacestation\n",
      "Loaded track 'Strand Of Oaks - Spacestation' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.414 to prevent clipping (peak was 2.292)\n",
      "Loaded track 'Strand Of Oaks - Spacestation' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.414 to prevent clipping (peak was 2.292)\n",
      "Saved chunk to musdb18_processed\\train\\Strand Of Oaks - Spacestation_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Strand Of Oaks - Spacestation_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  81%|████████  | 76/94 [03:46<00:57,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Strand Of Oaks - Spacestation_chunk_001.npz\n",
      "Completed processing Strand Of Oaks - Spacestation: 2 chunks processed, 0 failed\n",
      "Processing track: Sweet Lights - You Let Me Down\n",
      "Loaded track 'Sweet Lights - You Let Me Down' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.453 to prevent clipping (peak was 2.099)\n",
      "Loaded track 'Sweet Lights - You Let Me Down' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.453 to prevent clipping (peak was 2.099)\n",
      "Saved chunk to musdb18_processed\\train\\Sweet Lights - You Let Me Down_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Sweet Lights - You Let Me Down_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  82%|████████▏ | 77/94 [03:50<00:54,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Sweet Lights - You Let Me Down_chunk_001.npz\n",
      "Completed processing Sweet Lights - You Let Me Down: 2 chunks processed, 0 failed\n",
      "Processing track: Swinging Steaks - Lost My Way\n",
      "Loaded track 'Swinging Steaks - Lost My Way' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.593 to prevent clipping (peak was 1.603)\n",
      "Loaded track 'Swinging Steaks - Lost My Way' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.593 to prevent clipping (peak was 1.603)\n",
      "Saved chunk to musdb18_processed\\train\\Swinging Steaks - Lost My Way_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Swinging Steaks - Lost My Way_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  83%|████████▎ | 78/94 [03:53<00:51,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Swinging Steaks - Lost My Way_chunk_001.npz\n",
      "Completed processing Swinging Steaks - Lost My Way: 2 chunks processed, 0 failed\n",
      "Processing track: The Districts - Vermont\n",
      "Loaded track 'The Districts - Vermont' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.499 to prevent clipping (peak was 1.902)\n",
      "Loaded track 'The Districts - Vermont' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.499 to prevent clipping (peak was 1.902)\n",
      "Saved chunk to musdb18_processed\\train\\The Districts - Vermont_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\The Districts - Vermont_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  84%|████████▍ | 79/94 [03:56<00:48,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\The Districts - Vermont_chunk_001.npz\n",
      "Completed processing The Districts - Vermont: 2 chunks processed, 0 failed\n",
      "Processing track: The Long Wait - Back Home To Blue\n",
      "Loaded track 'The Long Wait - Back Home To Blue' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.480 to prevent clipping (peak was 1.979)\n",
      "Loaded track 'The Long Wait - Back Home To Blue' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.480 to prevent clipping (peak was 1.979)\n",
      "Saved chunk to musdb18_processed\\train\\The Long Wait - Back Home To Blue_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\The Long Wait - Back Home To Blue_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  85%|████████▌ | 80/94 [03:59<00:44,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\The Long Wait - Back Home To Blue_chunk_001.npz\n",
      "Completed processing The Long Wait - Back Home To Blue: 2 chunks processed, 0 failed\n",
      "Processing track: The Scarlet Brand - Les Fleurs Du Mal\n",
      "Loaded track 'The Scarlet Brand - Les Fleurs Du Mal' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.470 to prevent clipping (peak was 2.022)\n",
      "Loaded track 'The Scarlet Brand - Les Fleurs Du Mal' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.470 to prevent clipping (peak was 2.022)\n",
      "Saved chunk to musdb18_processed\\train\\The Scarlet Brand - Les Fleurs Du Mal_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\The Scarlet Brand - Les Fleurs Du Mal_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  86%|████████▌ | 81/94 [04:02<00:40,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\The Scarlet Brand - Les Fleurs Du Mal_chunk_001.npz\n",
      "Completed processing The Scarlet Brand - Les Fleurs Du Mal: 2 chunks processed, 0 failed\n",
      "Processing track: The So So Glos - Emergency\n",
      "Loaded track 'The So So Glos - Emergency' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.466 to prevent clipping (peak was 2.037)\n",
      "Loaded track 'The So So Glos - Emergency' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.466 to prevent clipping (peak was 2.037)\n",
      "Saved chunk to musdb18_processed\\train\\The So So Glos - Emergency_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\The So So Glos - Emergency_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  87%|████████▋ | 82/94 [04:05<00:37,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\The So So Glos - Emergency_chunk_001.npz\n",
      "Completed processing The So So Glos - Emergency: 2 chunks processed, 0 failed\n",
      "Processing track: The Wrong'Uns - Rothko\n",
      "Loaded track 'The Wrong'Uns - Rothko' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.538 to prevent clipping (peak was 1.765)\n",
      "Loaded track 'The Wrong'Uns - Rothko' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.538 to prevent clipping (peak was 1.765)\n",
      "Saved chunk to musdb18_processed\\train\\The Wrong'Uns - Rothko_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\The Wrong'Uns - Rothko_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  88%|████████▊ | 83/94 [04:08<00:34,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\The Wrong'Uns - Rothko_chunk_001.npz\n",
      "Completed processing The Wrong'Uns - Rothko: 2 chunks processed, 0 failed\n",
      "Processing track: Tim Taler - Stalker\n",
      "Loaded track 'Tim Taler - Stalker' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.606 to prevent clipping (peak was 1.568)\n",
      "Loaded track 'Tim Taler - Stalker' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.606 to prevent clipping (peak was 1.568)\n",
      "Saved chunk to musdb18_processed\\train\\Tim Taler - Stalker_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Tim Taler - Stalker_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  89%|████████▉ | 84/94 [04:11<00:30,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Tim Taler - Stalker_chunk_001.npz\n",
      "Completed processing Tim Taler - Stalker: 2 chunks processed, 0 failed\n",
      "Processing track: Titanium - Haunted Age\n",
      "Loaded track 'Titanium - Haunted Age' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.507 to prevent clipping (peak was 1.874)\n",
      "Loaded track 'Titanium - Haunted Age' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.507 to prevent clipping (peak was 1.874)\n",
      "Saved chunk to musdb18_processed\\train\\Titanium - Haunted Age_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Titanium - Haunted Age_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  90%|█████████ | 85/94 [04:15<00:28,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Titanium - Haunted Age_chunk_001.npz\n",
      "Completed processing Titanium - Haunted Age: 2 chunks processed, 0 failed\n",
      "Processing track: Traffic Experiment - Once More (With Feeling)\n",
      "Loaded track 'Traffic Experiment - Once More (With Feeling)' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.525 to prevent clipping (peak was 1.811)\n",
      "Loaded track 'Traffic Experiment - Once More (With Feeling)' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.525 to prevent clipping (peak was 1.811)\n",
      "Saved chunk to musdb18_processed\\train\\Traffic Experiment - Once More (With Feeling)_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Traffic Experiment - Once More (With Feeling)_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  91%|█████████▏| 86/94 [04:18<00:24,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Traffic Experiment - Once More (With Feeling)_chunk_001.npz\n",
      "Completed processing Traffic Experiment - Once More (With Feeling): 2 chunks processed, 0 failed\n",
      "Processing track: Traffic Experiment - Sirens\n",
      "Loaded track 'Traffic Experiment - Sirens' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.459 to prevent clipping (peak was 2.067)\n",
      "Loaded track 'Traffic Experiment - Sirens' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.459 to prevent clipping (peak was 2.067)\n",
      "Saved chunk to musdb18_processed\\train\\Traffic Experiment - Sirens_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Traffic Experiment - Sirens_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  93%|█████████▎| 87/94 [04:21<00:21,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Traffic Experiment - Sirens_chunk_001.npz\n",
      "Completed processing Traffic Experiment - Sirens: 2 chunks processed, 0 failed\n",
      "Processing track: Triviul - Angelsaint\n",
      "Loaded track 'Triviul - Angelsaint' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.449 to prevent clipping (peak was 2.115)\n",
      "Loaded track 'Triviul - Angelsaint' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.449 to prevent clipping (peak was 2.115)\n",
      "Saved chunk to musdb18_processed\\train\\Triviul - Angelsaint_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Triviul - Angelsaint_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  94%|█████████▎| 88/94 [04:24<00:18,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Triviul - Angelsaint_chunk_001.npz\n",
      "Completed processing Triviul - Angelsaint: 2 chunks processed, 0 failed\n",
      "Processing track: Triviul - Dorothy\n",
      "Loaded track 'Triviul - Dorothy' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.539 to prevent clipping (peak was 1.761)\n",
      "Loaded track 'Triviul - Dorothy' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.539 to prevent clipping (peak was 1.761)\n",
      "Saved chunk to musdb18_processed\\train\\Triviul - Dorothy_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Triviul - Dorothy_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  95%|█████████▍| 89/94 [04:27<00:15,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Triviul - Dorothy_chunk_001.npz\n",
      "Completed processing Triviul - Dorothy: 2 chunks processed, 0 failed\n",
      "Processing track: Voelund - Comfort Lives In Belief\n",
      "Loaded track 'Voelund - Comfort Lives In Belief' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.455 to prevent clipping (peak was 2.086)\n",
      "Loaded track 'Voelund - Comfort Lives In Belief' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.455 to prevent clipping (peak was 2.086)\n",
      "Saved chunk to musdb18_processed\\train\\Voelund - Comfort Lives In Belief_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Voelund - Comfort Lives In Belief_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  96%|█████████▌| 90/94 [04:30<00:12,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Voelund - Comfort Lives In Belief_chunk_001.npz\n",
      "Completed processing Voelund - Comfort Lives In Belief: 2 chunks processed, 0 failed\n",
      "Processing track: Wall Of Death - Femme\n",
      "Loaded track 'Wall Of Death - Femme' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.550 to prevent clipping (peak was 1.727)\n",
      "Loaded track 'Wall Of Death - Femme' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.550 to prevent clipping (peak was 1.727)\n",
      "Saved chunk to musdb18_processed\\train\\Wall Of Death - Femme_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Wall Of Death - Femme_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  97%|█████████▋| 91/94 [04:33<00:09,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Wall Of Death - Femme_chunk_001.npz\n",
      "Completed processing Wall Of Death - Femme: 2 chunks processed, 0 failed\n",
      "Processing track: Young Griffo - Blood To Bone\n",
      "Loaded track 'Young Griffo - Blood To Bone' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.454 to prevent clipping (peak was 2.092)\n",
      "Loaded track 'Young Griffo - Blood To Bone' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.454 to prevent clipping (peak was 2.092)\n",
      "Saved chunk to musdb18_processed\\train\\Young Griffo - Blood To Bone_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Young Griffo - Blood To Bone_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  98%|█████████▊| 92/94 [04:36<00:06,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Young Griffo - Blood To Bone_chunk_001.npz\n",
      "Completed processing Young Griffo - Blood To Bone: 2 chunks processed, 0 failed\n",
      "Processing track: Young Griffo - Facade\n",
      "Loaded track 'Young Griffo - Facade' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.527 to prevent clipping (peak was 1.804)\n",
      "Loaded track 'Young Griffo - Facade' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.527 to prevent clipping (peak was 1.804)\n",
      "Saved chunk to musdb18_processed\\train\\Young Griffo - Facade_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Young Griffo - Facade_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks:  99%|█████████▉| 93/94 [04:40<00:03,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Young Griffo - Facade_chunk_001.npz\n",
      "Completed processing Young Griffo - Facade: 2 chunks processed, 0 failed\n",
      "Processing track: Young Griffo - Pennies\n",
      "Loaded track 'Young Griffo - Pennies' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.424 to prevent clipping (peak was 2.240)\n",
      "Loaded track 'Young Griffo - Pennies' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.424 to prevent clipping (peak was 2.240)\n",
      "Saved chunk to musdb18_processed\\train\\Young Griffo - Pennies_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\train\\Young Griffo - Pennies_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train tracks: 100%|██████████| 94/94 [04:43<00:00,  3.01s/it]\n",
      "Processing train tracks: 100%|██████████| 94/94 [04:43<00:00,  3.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\train\\Young Griffo - Pennies_chunk_001.npz\n",
      "Completed processing Young Griffo - Pennies: 2 chunks processed, 0 failed\n",
      "\n",
      "TRAIN SET SUMMARY:\n",
      "Tracks processed: 94/94\n",
      "Chunks processed: 188/188\n",
      "Failed tracks: 0\n",
      "Processing time: 283.1 seconds\n",
      "\n",
      "================================================================================\n",
      "PHASE 2: Processing Test Set\n",
      "\n",
      "============================================================\n",
      "Processing TEST set: 50 tracks\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track: AM Contra - Heart Peripheral\n",
      "Loaded track 'AM Contra - Heart Peripheral' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.479 to prevent clipping (peak was 1.985)\n",
      "Loaded track 'AM Contra - Heart Peripheral' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.479 to prevent clipping (peak was 1.985)\n",
      "Saved chunk to musdb18_processed\\test\\AM Contra - Heart Peripheral_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\AM Contra - Heart Peripheral_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:   2%|▏         | 1/50 [00:03<02:32,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\AM Contra - Heart Peripheral_chunk_001.npz\n",
      "Completed processing AM Contra - Heart Peripheral: 2 chunks processed, 0 failed\n",
      "Processing track: Al James - Schoolboy Facination\n",
      "Loaded track 'Al James - Schoolboy Facination' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.408 to prevent clipping (peak was 2.328)\n",
      "Loaded track 'Al James - Schoolboy Facination' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.408 to prevent clipping (peak was 2.328)\n",
      "Saved chunk to musdb18_processed\\test\\Al James - Schoolboy Facination_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Al James - Schoolboy Facination_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:   4%|▍         | 2/50 [00:06<02:28,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Al James - Schoolboy Facination_chunk_001.npz\n",
      "Completed processing Al James - Schoolboy Facination: 2 chunks processed, 0 failed\n",
      "Processing track: Angels In Amplifiers - I'm Alright\n",
      "Loaded track 'Angels In Amplifiers - I'm Alright' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.458 to prevent clipping (peak was 2.075)\n",
      "Loaded track 'Angels In Amplifiers - I'm Alright' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.458 to prevent clipping (peak was 2.075)\n",
      "Saved chunk to musdb18_processed\\test\\Angels In Amplifiers - I'm Alright_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Angels In Amplifiers - I'm Alright_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:   6%|▌         | 3/50 [00:09<02:27,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Angels In Amplifiers - I'm Alright_chunk_001.npz\n",
      "Completed processing Angels In Amplifiers - I'm Alright: 2 chunks processed, 0 failed\n",
      "Processing track: Arise - Run Run Run\n",
      "Loaded track 'Arise - Run Run Run' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.529 to prevent clipping (peak was 1.796)\n",
      "Loaded track 'Arise - Run Run Run' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.529 to prevent clipping (peak was 1.796)\n",
      "Saved chunk to musdb18_processed\\test\\Arise - Run Run Run_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Arise - Run Run Run_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:   8%|▊         | 4/50 [00:12<02:24,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Arise - Run Run Run_chunk_001.npz\n",
      "Completed processing Arise - Run Run Run: 2 chunks processed, 0 failed\n",
      "Processing track: BKS - Bulldozer\n",
      "Loaded track 'BKS - Bulldozer' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.427 to prevent clipping (peak was 2.226)\n",
      "Loaded track 'BKS - Bulldozer' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.427 to prevent clipping (peak was 2.226)\n",
      "Saved chunk to musdb18_processed\\test\\BKS - Bulldozer_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\BKS - Bulldozer_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  10%|█         | 5/50 [00:15<02:22,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\BKS - Bulldozer_chunk_001.npz\n",
      "Completed processing BKS - Bulldozer: 2 chunks processed, 0 failed\n",
      "Processing track: BKS - Too Much\n",
      "Loaded track 'BKS - Too Much' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.507 to prevent clipping (peak was 1.875)\n",
      "Loaded track 'BKS - Too Much' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.507 to prevent clipping (peak was 1.875)\n",
      "Saved chunk to musdb18_processed\\test\\BKS - Too Much_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\BKS - Too Much_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  12%|█▏        | 6/50 [00:18<02:18,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\BKS - Too Much_chunk_001.npz\n",
      "Completed processing BKS - Too Much: 2 chunks processed, 0 failed\n",
      "Processing track: Ben Carrigan - We'll Talk About It All Tonight\n",
      "Loaded track 'Ben Carrigan - We'll Talk About It All Tonight' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.564 to prevent clipping (peak was 1.684)\n",
      "Loaded track 'Ben Carrigan - We'll Talk About It All Tonight' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.564 to prevent clipping (peak was 1.684)\n",
      "Saved chunk to musdb18_processed\\test\\Ben Carrigan - We'll Talk About It All Tonight_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Ben Carrigan - We'll Talk About It All Tonight_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  14%|█▍        | 7/50 [00:21<02:14,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Ben Carrigan - We'll Talk About It All Tonight_chunk_001.npz\n",
      "Completed processing Ben Carrigan - We'll Talk About It All Tonight: 2 chunks processed, 0 failed\n",
      "Processing track: Bobby Nobody - Stitch Up\n",
      "Loaded track 'Bobby Nobody - Stitch Up' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.545 to prevent clipping (peak was 1.743)\n",
      "Loaded track 'Bobby Nobody - Stitch Up' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.545 to prevent clipping (peak was 1.743)\n",
      "Saved chunk to musdb18_processed\\test\\Bobby Nobody - Stitch Up_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Bobby Nobody - Stitch Up_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  16%|█▌        | 8/50 [00:24<02:10,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Bobby Nobody - Stitch Up_chunk_001.npz\n",
      "Completed processing Bobby Nobody - Stitch Up: 2 chunks processed, 0 failed\n",
      "Processing track: Buitraker - Revo X\n",
      "Loaded track 'Buitraker - Revo X' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.438 to prevent clipping (peak was 2.168)\n",
      "Loaded track 'Buitraker - Revo X' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.438 to prevent clipping (peak was 2.168)\n",
      "Saved chunk to musdb18_processed\\test\\Buitraker - Revo X_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Buitraker - Revo X_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  18%|█▊        | 9/50 [00:28<02:09,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Buitraker - Revo X_chunk_001.npz\n",
      "Completed processing Buitraker - Revo X: 2 chunks processed, 0 failed\n",
      "Processing track: Carlos Gonzalez - A Place For Us\n",
      "Loaded track 'Carlos Gonzalez - A Place For Us' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.419 to prevent clipping (peak was 2.265)\n",
      "Loaded track 'Carlos Gonzalez - A Place For Us' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.419 to prevent clipping (peak was 2.265)\n",
      "Saved chunk to musdb18_processed\\test\\Carlos Gonzalez - A Place For Us_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Carlos Gonzalez - A Place For Us_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  20%|██        | 10/50 [00:31<02:04,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Carlos Gonzalez - A Place For Us_chunk_001.npz\n",
      "Completed processing Carlos Gonzalez - A Place For Us: 2 chunks processed, 0 failed\n",
      "Processing track: Cristina Vane - So Easy\n",
      "Loaded track 'Cristina Vane - So Easy' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.437 to prevent clipping (peak was 2.172)\n",
      "Loaded track 'Cristina Vane - So Easy' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.437 to prevent clipping (peak was 2.172)\n",
      "Saved chunk to musdb18_processed\\test\\Cristina Vane - So Easy_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Cristina Vane - So Easy_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  22%|██▏       | 11/50 [00:34<02:02,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Cristina Vane - So Easy_chunk_001.npz\n",
      "Completed processing Cristina Vane - So Easy: 2 chunks processed, 0 failed\n",
      "Processing track: Detsky Sad - Walkie Talkie\n",
      "Loaded track 'Detsky Sad - Walkie Talkie' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.533 to prevent clipping (peak was 1.781)\n",
      "Loaded track 'Detsky Sad - Walkie Talkie' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.533 to prevent clipping (peak was 1.781)\n",
      "Saved chunk to musdb18_processed\\test\\Detsky Sad - Walkie Talkie_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Detsky Sad - Walkie Talkie_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  24%|██▍       | 12/50 [00:37<01:56,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Detsky Sad - Walkie Talkie_chunk_001.npz\n",
      "Completed processing Detsky Sad - Walkie Talkie: 2 chunks processed, 0 failed\n",
      "Processing track: Enda Reilly - Cur An Long Ag Seol\n",
      "Loaded track 'Enda Reilly - Cur An Long Ag Seol' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.485 to prevent clipping (peak was 1.958)\n",
      "Loaded track 'Enda Reilly - Cur An Long Ag Seol' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.485 to prevent clipping (peak was 1.958)\n",
      "Saved chunk to musdb18_processed\\test\\Enda Reilly - Cur An Long Ag Seol_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Enda Reilly - Cur An Long Ag Seol_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  26%|██▌       | 13/50 [00:40<01:53,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Enda Reilly - Cur An Long Ag Seol_chunk_001.npz\n",
      "Completed processing Enda Reilly - Cur An Long Ag Seol: 2 chunks processed, 0 failed\n",
      "Processing track: Forkupines - Semantics\n",
      "Loaded track 'Forkupines - Semantics' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.364 to prevent clipping (peak was 2.608)\n",
      "Loaded track 'Forkupines - Semantics' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.364 to prevent clipping (peak was 2.608)\n",
      "Saved chunk to musdb18_processed\\test\\Forkupines - Semantics_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Forkupines - Semantics_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  28%|██▊       | 14/50 [00:43<01:51,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Forkupines - Semantics_chunk_001.npz\n",
      "Completed processing Forkupines - Semantics: 2 chunks processed, 0 failed\n",
      "Processing track: Georgia Wonder - Siren\n",
      "Loaded track 'Georgia Wonder - Siren' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.445 to prevent clipping (peak was 2.134)\n",
      "Loaded track 'Georgia Wonder - Siren' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.445 to prevent clipping (peak was 2.134)\n",
      "Saved chunk to musdb18_processed\\test\\Georgia Wonder - Siren_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Georgia Wonder - Siren_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  30%|███       | 15/50 [00:46<01:49,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Georgia Wonder - Siren_chunk_001.npz\n",
      "Completed processing Georgia Wonder - Siren: 2 chunks processed, 0 failed\n",
      "Processing track: Girls Under Glass - We Feel Alright\n",
      "Loaded track 'Girls Under Glass - We Feel Alright' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.471 to prevent clipping (peak was 2.019)\n",
      "Loaded track 'Girls Under Glass - We Feel Alright' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.471 to prevent clipping (peak was 2.019)\n",
      "Saved chunk to musdb18_processed\\test\\Girls Under Glass - We Feel Alright_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Girls Under Glass - We Feel Alright_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  32%|███▏      | 16/50 [00:49<01:45,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Girls Under Glass - We Feel Alright_chunk_001.npz\n",
      "Completed processing Girls Under Glass - We Feel Alright: 2 chunks processed, 0 failed\n",
      "Processing track: Hollow Ground - Ill Fate\n",
      "Loaded track 'Hollow Ground - Ill Fate' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.521 to prevent clipping (peak was 1.824)\n",
      "Loaded track 'Hollow Ground - Ill Fate' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.521 to prevent clipping (peak was 1.824)\n",
      "Saved chunk to musdb18_processed\\test\\Hollow Ground - Ill Fate_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Hollow Ground - Ill Fate_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  34%|███▍      | 17/50 [00:52<01:42,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Hollow Ground - Ill Fate_chunk_001.npz\n",
      "Completed processing Hollow Ground - Ill Fate: 2 chunks processed, 0 failed\n",
      "Processing track: James Elder & Mark M Thompson - The English Actor\n",
      "Loaded track 'James Elder & Mark M Thompson - The English Actor' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.542 to prevent clipping (peak was 1.753)\n",
      "Loaded track 'James Elder & Mark M Thompson - The English Actor' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.542 to prevent clipping (peak was 1.753)\n",
      "Saved chunk to musdb18_processed\\test\\James Elder & Mark M Thompson - The English Actor_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\James Elder & Mark M Thompson - The English Actor_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  36%|███▌      | 18/50 [00:56<01:42,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\James Elder & Mark M Thompson - The English Actor_chunk_001.npz\n",
      "Completed processing James Elder & Mark M Thompson - The English Actor: 2 chunks processed, 0 failed\n",
      "Processing track: Juliet's Rescue - Heartbeats\n",
      "Loaded track 'Juliet's Rescue - Heartbeats' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.465 to prevent clipping (peak was 2.043)\n",
      "Loaded track 'Juliet's Rescue - Heartbeats' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.465 to prevent clipping (peak was 2.043)\n",
      "Saved chunk to musdb18_processed\\test\\Juliet's Rescue - Heartbeats_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Juliet's Rescue - Heartbeats_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  38%|███▊      | 19/50 [00:59<01:39,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Juliet's Rescue - Heartbeats_chunk_001.npz\n",
      "Completed processing Juliet's Rescue - Heartbeats: 2 chunks processed, 0 failed\n",
      "Processing track: Little Chicago's Finest - My Own\n",
      "Loaded track 'Little Chicago's Finest - My Own' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.459 to prevent clipping (peak was 2.069)\n",
      "Loaded track 'Little Chicago's Finest - My Own' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.459 to prevent clipping (peak was 2.069)\n",
      "Saved chunk to musdb18_processed\\test\\Little Chicago's Finest - My Own_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Little Chicago's Finest - My Own_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  40%|████      | 20/50 [01:02<01:35,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Little Chicago's Finest - My Own_chunk_001.npz\n",
      "Completed processing Little Chicago's Finest - My Own: 2 chunks processed, 0 failed\n",
      "Processing track: Louis Cressy Band - Good Time\n",
      "Loaded track 'Louis Cressy Band - Good Time' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.427 to prevent clipping (peak was 2.226)\n",
      "Loaded track 'Louis Cressy Band - Good Time' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.427 to prevent clipping (peak was 2.226)\n",
      "Saved chunk to musdb18_processed\\test\\Louis Cressy Band - Good Time_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Louis Cressy Band - Good Time_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  42%|████▏     | 21/50 [01:05<01:31,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Louis Cressy Band - Good Time_chunk_001.npz\n",
      "Completed processing Louis Cressy Band - Good Time: 2 chunks processed, 0 failed\n",
      "Processing track: Lyndsey Ollard - Catching Up\n",
      "Loaded track 'Lyndsey Ollard - Catching Up' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.526 to prevent clipping (peak was 1.806)\n",
      "Loaded track 'Lyndsey Ollard - Catching Up' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.526 to prevent clipping (peak was 1.806)\n",
      "Saved chunk to musdb18_processed\\test\\Lyndsey Ollard - Catching Up_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Lyndsey Ollard - Catching Up_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  44%|████▍     | 22/50 [01:08<01:27,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Lyndsey Ollard - Catching Up_chunk_001.npz\n",
      "Completed processing Lyndsey Ollard - Catching Up: 2 chunks processed, 0 failed\n",
      "Processing track: M.E.R.C. Music - Knockout\n",
      "Loaded track 'M.E.R.C. Music - Knockout' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.477 to prevent clipping (peak was 1.992)\n",
      "Loaded track 'M.E.R.C. Music - Knockout' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.477 to prevent clipping (peak was 1.992)\n",
      "Saved chunk to musdb18_processed\\test\\M.E.R.C. Music - Knockout_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\M.E.R.C. Music - Knockout_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  46%|████▌     | 23/50 [01:12<01:25,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\M.E.R.C. Music - Knockout_chunk_001.npz\n",
      "Completed processing M.E.R.C. Music - Knockout: 2 chunks processed, 0 failed\n",
      "Processing track: Moosmusic - Big Dummy Shake\n",
      "Loaded track 'Moosmusic - Big Dummy Shake' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.384 to prevent clipping (peak was 2.472)\n",
      "Loaded track 'Moosmusic - Big Dummy Shake' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.384 to prevent clipping (peak was 2.472)\n",
      "Saved chunk to musdb18_processed\\test\\Moosmusic - Big Dummy Shake_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Moosmusic - Big Dummy Shake_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  48%|████▊     | 24/50 [01:15<01:22,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Moosmusic - Big Dummy Shake_chunk_001.npz\n",
      "Completed processing Moosmusic - Big Dummy Shake: 2 chunks processed, 0 failed\n",
      "Processing track: Motor Tapes - Shore\n",
      "Loaded track 'Motor Tapes - Shore' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.491 to prevent clipping (peak was 1.936)\n",
      "Loaded track 'Motor Tapes - Shore' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.491 to prevent clipping (peak was 1.936)\n",
      "Saved chunk to musdb18_processed\\test\\Motor Tapes - Shore_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Motor Tapes - Shore_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  50%|█████     | 25/50 [01:18<01:18,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Motor Tapes - Shore_chunk_001.npz\n",
      "Completed processing Motor Tapes - Shore: 2 chunks processed, 0 failed\n",
      "Processing track: Mu - Too Bright\n",
      "Loaded track 'Mu - Too Bright' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.437 to prevent clipping (peak was 2.174)\n",
      "Loaded track 'Mu - Too Bright' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.437 to prevent clipping (peak was 2.174)\n",
      "Saved chunk to musdb18_processed\\test\\Mu - Too Bright_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Mu - Too Bright_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  52%|█████▏    | 26/50 [01:21<01:15,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Mu - Too Bright_chunk_001.npz\n",
      "Completed processing Mu - Too Bright: 2 chunks processed, 0 failed\n",
      "Processing track: Nerve 9 - Pray For The Rain\n",
      "Loaded track 'Nerve 9 - Pray For The Rain' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.550 to prevent clipping (peak was 1.728)\n",
      "Loaded track 'Nerve 9 - Pray For The Rain' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.550 to prevent clipping (peak was 1.728)\n",
      "Saved chunk to musdb18_processed\\test\\Nerve 9 - Pray For The Rain_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Nerve 9 - Pray For The Rain_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  54%|█████▍    | 27/50 [01:24<01:12,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Nerve 9 - Pray For The Rain_chunk_001.npz\n",
      "Completed processing Nerve 9 - Pray For The Rain: 2 chunks processed, 0 failed\n",
      "Processing track: PR - Happy Daze\n",
      "Loaded track 'PR - Happy Daze' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.584 to prevent clipping (peak was 1.627)\n",
      "Loaded track 'PR - Happy Daze' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.584 to prevent clipping (peak was 1.627)\n",
      "Saved chunk to musdb18_processed\\test\\PR - Happy Daze_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\PR - Happy Daze_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  56%|█████▌    | 28/50 [01:28<01:10,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\PR - Happy Daze_chunk_001.npz\n",
      "Completed processing PR - Happy Daze: 2 chunks processed, 0 failed\n",
      "Processing track: PR - Oh No\n",
      "Loaded track 'PR - Oh No' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.573 to prevent clipping (peak was 1.658)\n",
      "Loaded track 'PR - Oh No' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.573 to prevent clipping (peak was 1.658)\n",
      "Saved chunk to musdb18_processed\\test\\PR - Oh No_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\PR - Oh No_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  58%|█████▊    | 29/50 [01:31<01:06,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\PR - Oh No_chunk_001.npz\n",
      "Completed processing PR - Oh No: 2 chunks processed, 0 failed\n",
      "Processing track: Punkdisco - Oral Hygiene\n",
      "Loaded track 'Punkdisco - Oral Hygiene' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.574 to prevent clipping (peak was 1.655)\n",
      "Loaded track 'Punkdisco - Oral Hygiene' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.574 to prevent clipping (peak was 1.655)\n",
      "Saved chunk to musdb18_processed\\test\\Punkdisco - Oral Hygiene_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Punkdisco - Oral Hygiene_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  60%|██████    | 30/50 [01:34<01:04,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Punkdisco - Oral Hygiene_chunk_001.npz\n",
      "Completed processing Punkdisco - Oral Hygiene: 2 chunks processed, 0 failed\n",
      "Processing track: Raft Monk - Tiring\n",
      "Loaded track 'Raft Monk - Tiring' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.470 to prevent clipping (peak was 2.022)\n",
      "Loaded track 'Raft Monk - Tiring' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.470 to prevent clipping (peak was 2.022)\n",
      "Saved chunk to musdb18_processed\\test\\Raft Monk - Tiring_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Raft Monk - Tiring_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  62%|██████▏   | 31/50 [01:37<01:01,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Raft Monk - Tiring_chunk_001.npz\n",
      "Completed processing Raft Monk - Tiring: 2 chunks processed, 0 failed\n",
      "Processing track: Sambasevam Shanmugam - Kaathaadi\n",
      "Loaded track 'Sambasevam Shanmugam - Kaathaadi' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.511 to prevent clipping (peak was 1.860)\n",
      "Loaded track 'Sambasevam Shanmugam - Kaathaadi' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.511 to prevent clipping (peak was 1.860)\n",
      "Saved chunk to musdb18_processed\\test\\Sambasevam Shanmugam - Kaathaadi_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Sambasevam Shanmugam - Kaathaadi_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  64%|██████▍   | 32/50 [01:40<00:57,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Sambasevam Shanmugam - Kaathaadi_chunk_001.npz\n",
      "Completed processing Sambasevam Shanmugam - Kaathaadi: 2 chunks processed, 0 failed\n",
      "Processing track: Secretariat - Borderline\n",
      "Loaded track 'Secretariat - Borderline' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.479 to prevent clipping (peak was 1.984)\n",
      "Loaded track 'Secretariat - Borderline' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.479 to prevent clipping (peak was 1.984)\n",
      "Saved chunk to musdb18_processed\\test\\Secretariat - Borderline_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Secretariat - Borderline_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  66%|██████▌   | 33/50 [01:44<00:55,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Secretariat - Borderline_chunk_001.npz\n",
      "Completed processing Secretariat - Borderline: 2 chunks processed, 0 failed\n",
      "Processing track: Secretariat - Over The Top\n",
      "Loaded track 'Secretariat - Over The Top' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.591 to prevent clipping (peak was 1.608)\n",
      "Loaded track 'Secretariat - Over The Top' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.591 to prevent clipping (peak was 1.608)\n",
      "Saved chunk to musdb18_processed\\test\\Secretariat - Over The Top_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Secretariat - Over The Top_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  68%|██████▊   | 34/50 [01:47<00:51,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Secretariat - Over The Top_chunk_001.npz\n",
      "Completed processing Secretariat - Over The Top: 2 chunks processed, 0 failed\n",
      "Processing track: Side Effects Project - Sing With Me\n",
      "Loaded track 'Side Effects Project - Sing With Me' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.425 to prevent clipping (peak was 2.234)\n",
      "Loaded track 'Side Effects Project - Sing With Me' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.425 to prevent clipping (peak was 2.234)\n",
      "Saved chunk to musdb18_processed\\test\\Side Effects Project - Sing With Me_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Side Effects Project - Sing With Me_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  70%|███████   | 35/50 [01:50<00:48,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Side Effects Project - Sing With Me_chunk_001.npz\n",
      "Completed processing Side Effects Project - Sing With Me: 2 chunks processed, 0 failed\n",
      "Processing track: Signe Jakobsen - What Have You Done To Me\n",
      "Loaded track 'Signe Jakobsen - What Have You Done To Me' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.476 to prevent clipping (peak was 1.996)\n",
      "Loaded track 'Signe Jakobsen - What Have You Done To Me' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.476 to prevent clipping (peak was 1.996)\n",
      "Saved chunk to musdb18_processed\\test\\Signe Jakobsen - What Have You Done To Me_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Signe Jakobsen - What Have You Done To Me_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  72%|███████▏  | 36/50 [01:53<00:43,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Signe Jakobsen - What Have You Done To Me_chunk_001.npz\n",
      "Completed processing Signe Jakobsen - What Have You Done To Me: 2 chunks processed, 0 failed\n",
      "Processing track: Skelpolu - Resurrection\n",
      "Loaded track 'Skelpolu - Resurrection' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.433 to prevent clipping (peak was 2.196)\n",
      "Loaded track 'Skelpolu - Resurrection' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.433 to prevent clipping (peak was 2.196)\n",
      "Saved chunk to musdb18_processed\\test\\Skelpolu - Resurrection_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Skelpolu - Resurrection_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  74%|███████▍  | 37/50 [01:56<00:38,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Skelpolu - Resurrection_chunk_001.npz\n",
      "Completed processing Skelpolu - Resurrection: 2 chunks processed, 0 failed\n",
      "Processing track: Speak Softly - Broken Man\n",
      "Loaded track 'Speak Softly - Broken Man' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.406 to prevent clipping (peak was 2.338)\n",
      "Loaded track 'Speak Softly - Broken Man' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.406 to prevent clipping (peak was 2.338)\n",
      "Saved chunk to musdb18_processed\\test\\Speak Softly - Broken Man_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Speak Softly - Broken Man_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  76%|███████▌  | 38/50 [01:58<00:34,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Speak Softly - Broken Man_chunk_001.npz\n",
      "Completed processing Speak Softly - Broken Man: 2 chunks processed, 0 failed\n",
      "Processing track: Speak Softly - Like Horses\n",
      "Loaded track 'Speak Softly - Like Horses' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.438 to prevent clipping (peak was 2.168)\n",
      "Loaded track 'Speak Softly - Like Horses' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.438 to prevent clipping (peak was 2.168)\n",
      "Saved chunk to musdb18_processed\\test\\Speak Softly - Like Horses_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Speak Softly - Like Horses_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  78%|███████▊  | 39/50 [02:01<00:30,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Speak Softly - Like Horses_chunk_001.npz\n",
      "Completed processing Speak Softly - Like Horses: 2 chunks processed, 0 failed\n",
      "Processing track: The Doppler Shift - Atrophy\n",
      "Loaded track 'The Doppler Shift - Atrophy' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.390 to prevent clipping (peak was 2.434)\n",
      "Loaded track 'The Doppler Shift - Atrophy' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.390 to prevent clipping (peak was 2.434)\n",
      "Saved chunk to musdb18_processed\\test\\The Doppler Shift - Atrophy_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\The Doppler Shift - Atrophy_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  80%|████████  | 40/50 [02:03<00:26,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\The Doppler Shift - Atrophy_chunk_001.npz\n",
      "Completed processing The Doppler Shift - Atrophy: 2 chunks processed, 0 failed\n",
      "Processing track: The Easton Ellises (Baumi) - SDRNR\n",
      "Loaded track 'The Easton Ellises (Baumi) - SDRNR' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.507 to prevent clipping (peak was 1.876)\n",
      "Loaded track 'The Easton Ellises (Baumi) - SDRNR' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.507 to prevent clipping (peak was 1.876)\n",
      "Saved chunk to musdb18_processed\\test\\The Easton Ellises (Baumi) - SDRNR_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\The Easton Ellises (Baumi) - SDRNR_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  82%|████████▏ | 41/50 [02:06<00:23,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\The Easton Ellises (Baumi) - SDRNR_chunk_001.npz\n",
      "Completed processing The Easton Ellises (Baumi) - SDRNR: 2 chunks processed, 0 failed\n",
      "Processing track: The Easton Ellises - Falcon 69\n",
      "Loaded track 'The Easton Ellises - Falcon 69' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.485 to prevent clipping (peak was 1.958)\n",
      "Loaded track 'The Easton Ellises - Falcon 69' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.485 to prevent clipping (peak was 1.958)\n",
      "Saved chunk to musdb18_processed\\test\\The Easton Ellises - Falcon 69_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\The Easton Ellises - Falcon 69_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  84%|████████▍ | 42/50 [02:08<00:20,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\The Easton Ellises - Falcon 69_chunk_001.npz\n",
      "Completed processing The Easton Ellises - Falcon 69: 2 chunks processed, 0 failed\n",
      "Processing track: The Long Wait - Dark Horses\n",
      "Loaded track 'The Long Wait - Dark Horses' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.458 to prevent clipping (peak was 2.073)\n",
      "Loaded track 'The Long Wait - Dark Horses' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.458 to prevent clipping (peak was 2.073)\n",
      "Saved chunk to musdb18_processed\\test\\The Long Wait - Dark Horses_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\The Long Wait - Dark Horses_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  86%|████████▌ | 43/50 [02:11<00:18,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\The Long Wait - Dark Horses_chunk_001.npz\n",
      "Completed processing The Long Wait - Dark Horses: 2 chunks processed, 0 failed\n",
      "Processing track: The Mountaineering Club - Mallory\n",
      "Loaded track 'The Mountaineering Club - Mallory' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.418 to prevent clipping (peak was 2.271)\n",
      "Loaded track 'The Mountaineering Club - Mallory' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.418 to prevent clipping (peak was 2.271)\n",
      "Saved chunk to musdb18_processed\\test\\The Mountaineering Club - Mallory_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\The Mountaineering Club - Mallory_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  88%|████████▊ | 44/50 [02:13<00:15,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\The Mountaineering Club - Mallory_chunk_001.npz\n",
      "Completed processing The Mountaineering Club - Mallory: 2 chunks processed, 0 failed\n",
      "Processing track: The Sunshine Garcia Band - For I Am The Moon\n",
      "Loaded track 'The Sunshine Garcia Band - For I Am The Moon' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.648 to prevent clipping (peak was 1.467)\n",
      "Loaded track 'The Sunshine Garcia Band - For I Am The Moon' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.648 to prevent clipping (peak was 1.467)\n",
      "Saved chunk to musdb18_processed\\test\\The Sunshine Garcia Band - For I Am The Moon_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\The Sunshine Garcia Band - For I Am The Moon_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  90%|█████████ | 45/50 [02:16<00:12,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\The Sunshine Garcia Band - For I Am The Moon_chunk_001.npz\n",
      "Completed processing The Sunshine Garcia Band - For I Am The Moon: 2 chunks processed, 0 failed\n",
      "Processing track: Timboz - Pony\n",
      "Loaded track 'Timboz - Pony' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.519 to prevent clipping (peak was 1.829)\n",
      "Loaded track 'Timboz - Pony' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.519 to prevent clipping (peak was 1.829)\n",
      "Saved chunk to musdb18_processed\\test\\Timboz - Pony_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Timboz - Pony_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  92%|█████████▏| 46/50 [02:18<00:10,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Timboz - Pony_chunk_001.npz\n",
      "Completed processing Timboz - Pony: 2 chunks processed, 0 failed\n",
      "Processing track: Tom McKenzie - Directions\n",
      "Loaded track 'Tom McKenzie - Directions' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.464 to prevent clipping (peak was 2.046)\n",
      "Loaded track 'Tom McKenzie - Directions' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.464 to prevent clipping (peak was 2.046)\n",
      "Saved chunk to musdb18_processed\\test\\Tom McKenzie - Directions_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Tom McKenzie - Directions_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  94%|█████████▍| 47/50 [02:21<00:07,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Tom McKenzie - Directions_chunk_001.npz\n",
      "Completed processing Tom McKenzie - Directions: 2 chunks processed, 0 failed\n",
      "Processing track: Triviul feat. The Fiend - Widow\n",
      "Loaded track 'Triviul feat. The Fiend - Widow' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.526 to prevent clipping (peak was 1.806)\n",
      "Loaded track 'Triviul feat. The Fiend - Widow' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.526 to prevent clipping (peak was 1.806)\n",
      "Saved chunk to musdb18_processed\\test\\Triviul feat. The Fiend - Widow_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Triviul feat. The Fiend - Widow_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  96%|█████████▌| 48/50 [02:23<00:05,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Triviul feat. The Fiend - Widow_chunk_001.npz\n",
      "Completed processing Triviul feat. The Fiend - Widow: 2 chunks processed, 0 failed\n",
      "Processing track: We Fell From The Sky - Not You\n",
      "Loaded track 'We Fell From The Sky - Not You' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.471 to prevent clipping (peak was 2.018)\n",
      "Loaded track 'We Fell From The Sky - Not You' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.471 to prevent clipping (peak was 2.018)\n",
      "Saved chunk to musdb18_processed\\test\\We Fell From The Sky - Not You_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\We Fell From The Sky - Not You_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks:  98%|█████████▊| 49/50 [02:26<00:02,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\We Fell From The Sky - Not You_chunk_001.npz\n",
      "Completed processing We Fell From The Sky - Not You: 2 chunks processed, 0 failed\n",
      "Processing track: Zeno - Signs\n",
      "Loaded track 'Zeno - Signs' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.513 to prevent clipping (peak was 1.850)\n",
      "Loaded track 'Zeno - Signs' with sources: ['vocals', 'drums', 'bass', 'other']\n",
      "Scaled mixture by 0.513 to prevent clipping (peak was 1.850)\n",
      "Saved chunk to musdb18_processed\\test\\Zeno - Signs_chunk_000.npz\n",
      "Saved chunk to musdb18_processed\\test\\Zeno - Signs_chunk_000.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test tracks: 100%|██████████| 50/50 [02:29<00:00,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to musdb18_processed\\test\\Zeno - Signs_chunk_001.npz\n",
      "Completed processing Zeno - Signs: 2 chunks processed, 0 failed\n",
      "\n",
      "TEST SET SUMMARY:\n",
      "Tracks processed: 50/50\n",
      "Chunks processed: 100/100\n",
      "Failed tracks: 0\n",
      "Processing time: 149.1 seconds\n",
      "\n",
      "================================================================================\n",
      " FULL DATASET PREPROCESSING COMPLETED!\n",
      "================================================================================\n",
      "\n",
      "OVERALL SUMMARY:\n",
      " Tracks processed: 144/144\n",
      " Chunks processed: 288/288\n",
      " Failed tracks: 0\n",
      " Failed chunks: 0\n",
      "  Total processing time: 0.1 hours (7.2 minutes)\n",
      " Track success rate: 100.0%\n",
      " Chunk success rate: 100.0%\n",
      "\n",
      " Generating processing report...\n",
      "\n",
      "Processing report saved to: musdb18_processed\\preprocessing_report.json\n",
      "\n",
      " OUTPUT FILES:\n",
      "Training chunks: 188 files in musdb18_processed/train/\n",
      "Test chunks: 100 files in musdb18_processed/test/\n",
      "Processing report: musdb18_processed/preprocessing_report.json\n",
      " Estimated disk usage: 4.0 GB\n",
      "\n",
      " Dataset preprocessing completed successfully!\n",
      "Both train and test sets underwent identical preprocessing pipelines.\n",
      "Data is ready for source separation model training and evaluation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute full dataset preprocessing\n",
    "print(\" STARTING FULL MUSDB18 DATASET PREPROCESSING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Record overall start time\n",
    "overall_start_time = time.time()\n",
    "\n",
    "# Process training set\n",
    "print(\"PHASE 1: Processing Training Set\")\n",
    "train_summary = preprocess_dataset_subset(\n",
    "    tracks=mus_train,\n",
    "    subset_name='train',\n",
    "    config=config,\n",
    "    base_output_dir=base_output_dir,\n",
    "    apply_augmentations=False  # Set to True if you want augmentations for training\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Process test set  \n",
    "print(\"PHASE 2: Processing Test Set\")\n",
    "test_summary = preprocess_dataset_subset(\n",
    "    tracks=mus_test,\n",
    "    subset_name='test',\n",
    "    config=config,\n",
    "    base_output_dir=base_output_dir,\n",
    "    apply_augmentations=False  # Typically no augmentations for test set\n",
    ")\n",
    "\n",
    "# Calculate total processing time\n",
    "total_time = time.time() - overall_start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" FULL DATASET PREPROCESSING COMPLETED!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Print comprehensive summary\n",
    "overall_summary = {\n",
    "    'total_tracks': train_summary['total_tracks'] + test_summary['total_tracks'],\n",
    "    'processed_tracks': train_summary['processed_tracks'] + test_summary['processed_tracks'],\n",
    "    'failed_tracks': train_summary['failed_tracks'] + test_summary['failed_tracks'],\n",
    "    'total_chunks': train_summary['total_chunks'] + test_summary['total_chunks'],\n",
    "    'processed_chunks': train_summary['processed_chunks'] + test_summary['processed_chunks'],\n",
    "    'failed_chunks': train_summary['failed_chunks'] + test_summary['failed_chunks']\n",
    "}\n",
    "\n",
    "print(f\"\\nOVERALL SUMMARY:\")\n",
    "print(f\" Tracks processed: {overall_summary['processed_tracks']}/{overall_summary['total_tracks']}\")\n",
    "print(f\" Chunks processed: {overall_summary['processed_chunks']}/{overall_summary['total_chunks']}\")\n",
    "print(f\" Failed tracks: {overall_summary['failed_tracks']}\")\n",
    "print(f\" Failed chunks: {overall_summary['failed_chunks']}\")\n",
    "print(f\"  Total processing time: {total_time/3600:.1f} hours ({total_time/60:.1f} minutes)\")\n",
    "\n",
    "# Calculate success rates\n",
    "track_success_rate = (overall_summary['processed_tracks'] / overall_summary['total_tracks']) * 100\n",
    "chunk_success_rate = (overall_summary['processed_chunks'] / overall_summary['total_chunks']) * 100\n",
    "\n",
    "print(f\" Track success rate: {track_success_rate:.1f}%\")\n",
    "print(f\" Chunk success rate: {chunk_success_rate:.1f}%\")\n",
    "\n",
    "# Save comprehensive report\n",
    "print(f\"\\n Generating processing report...\")\n",
    "report = save_processing_report(train_summary, test_summary, config, base_output_dir)\n",
    "\n",
    "# List output files\n",
    "train_files = list((base_output_dir / 'train').glob(\"*.npz\"))\n",
    "test_files = list((base_output_dir / 'test').glob(\"*.npz\"))\n",
    "\n",
    "print(f\"\\n OUTPUT FILES:\")\n",
    "print(f\"Training chunks: {len(train_files)} files in {base_output_dir}/train/\")\n",
    "print(f\"Test chunks: {len(test_files)} files in {base_output_dir}/test/\")\n",
    "print(f\"Processing report: {base_output_dir}/preprocessing_report.json\")\n",
    "\n",
    "# Estimate disk usage\n",
    "if train_files and test_files:\n",
    "    sample_file_size = train_files[0].stat().st_size / (1024*1024)  # MB\n",
    "    total_size_mb = (len(train_files) + len(test_files)) * sample_file_size\n",
    "    print(f\" Estimated disk usage: {total_size_mb/1024:.1f} GB\")\n",
    "\n",
    "print(f\"\\n Dataset preprocessing completed successfully!\")\n",
    "print(f\"Both train and test sets underwent identical preprocessing pipelines.\")\n",
    "print(f\"Data is ready for source separation model training and evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e9ae29",
   "metadata": {},
   "source": [
    "## Optional: Custom Preprocessing Configurations\n",
    "\n",
    "You can modify the preprocessing configuration before running the batch processing to suit your specific needs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2256acd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration options available above.\n",
      "Current settings:\n",
      "  FFT size: 4096\n",
      "  Hop length: 1024\n",
      "  Chunk length: 4.0s\n",
      "  Overlap: 0.0\n",
      "  Frequency bands: [0, 1500, 6000, 22050]\n",
      "  Augmentations enabled: False\n",
      "\n",
      "To modify settings, uncomment and edit the desired configuration above, then re-run this cell.\n"
     ]
    }
   ],
   "source": [
    "# Optional: Modify preprocessing configuration\n",
    "# Uncomment and modify any of these settings before running the full preprocessing\n",
    "\n",
    "# Example configurations for different use cases:\n",
    "\n",
    "# 1. High-resolution configuration (for better quality, more disk space)\n",
    "# config.n_fft = 8192\n",
    "# config.hop_length = config.n_fft // 8\n",
    "# config.chunk_len = 8.0  # Longer chunks\n",
    "\n",
    "# 2. Fast processing configuration (for quick experiments)\n",
    "# config.n_fft = 2048\n",
    "# config.hop_length = config.n_fft // 4\n",
    "# config.chunk_len = 2.0  # Shorter chunks\n",
    "\n",
    "# 3. Overlapping chunks configuration (for more training data)\n",
    "# config.overlap = 0.5  # 50% overlap between chunks\n",
    "\n",
    "# 4. Enable data augmentation for training set only\n",
    "# config.enable_random_gain = True\n",
    "# config.enable_add_noise = True\n",
    "\n",
    "# 5. Different frequency bands configuration\n",
    "# config.band_edges_hz = [0, 500, 2000, 8000, 22050]  # 4 bands instead of 3\n",
    "\n",
    "print(\"Configuration options available above.\")\n",
    "print(\"Current settings:\")\n",
    "print(f\"  FFT size: {config.n_fft}\")\n",
    "print(f\"  Hop length: {config.hop_length}\")  \n",
    "print(f\"  Chunk length: {config.chunk_len}s\")\n",
    "print(f\"  Overlap: {config.overlap}\")\n",
    "print(f\"  Frequency bands: {config.band_edges_hz}\")\n",
    "print(f\"  Augmentations enabled: {any([config.enable_random_gain, config.enable_add_noise, config.enable_time_stretch, config.enable_pitch_shift])}\")\n",
    "\n",
    "print(\"\\nTo modify settings, uncomment and edit the desired configuration above, then re-run this cell.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
